{"title": "Structure-guided function-level code generation with LLMs via UML activity diagrams", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "B Wan, Z Wei, S Wang, J Huang, C Hu- Neurocomputing, 2025\nDespite substantial advancements in function-level code generation powered by \nLarge Language Models (LLMs), a fundamental challenge remains: reducing the \nuncertainty in the code generation process from requirements to enable LLMs to", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0925231225031741&hl=vi&sa=X&d=9237739070767836864&ei=eS5Nae7jO4aw6rQPkNu46Ao&scisig=ALhkC2SKdGHlGlqrMKr9UWmgUCZN&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ALhkC2T2gGOcVPTEcMFcARghNUJN&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "VDMPAGR: A vulnerability detection model based on pointer analysis and graph representation", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Graph"], "data": "Y Dong, S Liu, X Liu, M Chen, S Wang, Y Feng- Information and Software, 2025\nContext: Software vulnerabilities pose a major threat to software security. Deep \nlearning-based vulnerability detection models have demonstrated notable \nadvantages, particularly in terms of automation and accuracy. Among these, graph", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950584925003210&hl=vi&sa=X&d=558143430722896337&ei=eS5Nae7jO4aw6rQPkNu46Ao&scisig=ALhkC2Q-zlQbenNHcC1nYe1IeGcP&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ALhkC2T2gGOcVPTEcMFcARghNUJN&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "SGCR: A Specification-Grounded Framework for Trustworthy LLM Code Review", "first_label": ["LLM", "Code Review", "Code"], "second_label": [], "data": "K Wang, B Mao, S Jia, Y Ding, D Han, T Ma, B Cao- arXiv preprint arXiv:2512.17540, 2025\nAutomating code review with Large Language Models (LLMs) shows immense \npromise, yet practical adoption is hampered by their lack of reliability, context-\nawareness, and control. To address this, we propose Specification-Grounded Code", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.17540&hl=vi&sa=X&d=16382589271726736633&ei=eS5Nae7jO4aw6rQPkNu46Ao&scisig=ALhkC2Rx_2I5F67w4_nJO52_b37Z&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ALhkC2T2gGOcVPTEcMFcARghNUJN&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "AI-Powered Unit Test Generation via Multi-LLM Chaining: A Case Study With GPT-4o, Gemini, and Claude-3.5", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "C Kumar, US Ponaka, PVLN Naidu, P Bhuvaneswari- IEEE Access, 2025\nSoftware testing is a crucial activity in the software development cycle, as it verifies \ncode correctness, reliability, and maintainabilily. Unit testing involves verifying the \ncorrectness of the individual components of a program. Manually writing these tests\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11269709/&hl=vi&sa=X&d=12530224562241630230&ei=eS5Nae7jO4aw6rQPkNu46Ao&scisig=ALhkC2QRRbOSkropLAmn1kMJTExK&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ALhkC2T2gGOcVPTEcMFcARghNUJN&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Evaluating and improving LLM-based competitive program generation", "first_label": ["LLM"], "second_label": ["Generation"], "data": "M Wei, Z Li, X Chen, M Zheng, Z Qu, C Yu, S Chen- Information and Software, 2025\nContext: Due to the demand for strong algorithmic reasoning, complex logic \nimplementation, and strict adherence to input/output formats and resource \nconstraints, competitive programming generation by large language models (LLMs)", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950584925003167&hl=vi&sa=X&d=5709124783036459514&ei=H7ZLabbnE7ux6rQPi5qW2AE&scisig=ALhkC2RbIKQLHP2C9FQAkypoxHIi&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ALhkC2T2gGOcVPTEcMFcARghNUJN&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Adapting Language Models for Low-Resource Programming Languages", "first_label": ["LLM"], "second_label": [], "data": "A Singha, M Singh, H Hasanbeig, A Radhakrishna- NeurIPS 2025 Fourth Workshop on\nLarge Language Models (LLMs) have achieved remarkable success in code \ngeneration, yet their capabilities remain predominantly concentrated in well-\nresourced programming languages such as Python and Java. In contrast, low\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3D2ctRK8h3AZ&hl=vi&sa=X&d=10639384588679978541&ei=H7ZLabbnE7ux6rQPi5qW2AE&scisig=ALhkC2TU1E8-xJojBcX0Q0YHF0cb&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ALhkC2T2gGOcVPTEcMFcARghNUJN&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
