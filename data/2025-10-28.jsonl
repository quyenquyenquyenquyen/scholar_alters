{"title": "A Scalable Vulnerability Detection System with Multi-View Graph Representations", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Graph"], "data": "S Dou, H Zheng, J Shan, Y Wu, D Zou, X Huang, Y Liu- ACM Transactions on, 2025\nDeep learning (DL) has been extensively utilized in source code vulnerability \ndetection due to its robust automatic feature extraction capabilities. To achieve \nscalable vulnerability scanning, some prior studies intend to process the source code", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3770075&hl=vi&sa=X&d=14953216934661661615&ei=GP3_aPjGINWY6rQPrbXRgQY&scisig=ABGrvjIFKzTAARKmQs4FcWCEoWpB&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Enhancing Domain-Specific Code Completion via Collaborative Inference with Large and Small Language Models", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "J Yu, Z Gao, L Bao, Z Liu- ACM Transactions on Software Engineering and, 2025\nLarge language model-based code completion has demonstrated excellent \nperformance, but still encounters challenges in capturing domain-specific knowledge \nfor more precise completion within specific domains, ie, domain-specific code", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3770748&hl=vi&sa=X&d=2019769577165862416&ei=GP3_aPjGINWY6rQPrbXRgQY&scisig=ABGrvjKO1fKaLDZwwCDDcSmDx0Da&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "ALMAS: an autonomous llm-based multi-agent software engineering framework", "first_label": ["LLM"], "second_label": ["Agent"], "data": "V Tawosi, K Ramani, S Alamir, X Liu- arXiv preprint arXiv:2510.03463, 2025\nMulti-agent Large Language Model (LLM) systems have been leading the way in \napplied LLM research across a number of fields. One notable area is software \ndevelopment, where researchers have advanced the automation of code", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.03463&hl=vi&sa=X&d=6189494284468520954&ei=GP3_aPjGINWY6rQPrbXRgQY&scisig=ABGrvjJrdVeB80cic_brCTfqWIPK&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Improving the Efficiency of LLM Agent Systems through Trajectory Reduction", "first_label": ["LLM"], "second_label": ["Agent"], "data": "YA Xiao, P Gao, C Peng, Y Xiong- arXiv preprint arXiv:2509.23586, 2025\nMulti-turn agent systems based on Large Language Models (LLMs) have been \nincreasingly popular for software engineering tasks. While LLM agents show decent \neffectiveness, the high computational cost of input tokens due to the ever-growing", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23586%3F&hl=vi&sa=X&d=12596444921036280365&ei=GP3_aPjGINWY6rQPrbXRgQY&scisig=ABGrvjLC0C_0GltjgtJTt8p-QsJp&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "LLM Agents for Automated Dependency Upgrades", "first_label": ["LLM"], "second_label": ["Agent"], "data": "V Tawosi, S Alamir, X Liu, M Veloso- arXiv preprint arXiv:2510.03480, 2025\nAs a codebase expands over time, its library dependencies can become outdated \nand require updates to maintain innovation and security. However, updating a library \ncan introduce breaking changes in the code, necessitating significant developer time", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.03480&hl=vi&sa=X&d=6490656773391404708&ei=GP3_aPjGINWY6rQPrbXRgQY&scisig=ABGrvjLTI-aGv2gyB5kKiU57yoCH&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Learning Project-wise Subsequent Code Edits via Interleaving Neural-based Induction and Tool-based Deduction", "first_label": ["Code"], "second_label": [], "data": "C Liu, Y Lin, Y Huang, J Chang, B Qi, B Jiang, Z Huang\nIn industrial and open-source software engineering tasks, developers often perform \nproject-wise code editing tasks, including feature enhancement, refactoring, and bug \nfixing, where the leading AI models are expected to support the productivity. Hence", "link": "https://scholar.google.com/scholar_url?url=http://linyun.info/publications/ase25.pdf&hl=vi&sa=X&d=10948765072096116511&ei=GP3_aPjGINWY6rQPrbXRgQY&scisig=ABGrvjKBXCNGAlGU6UXYxWVhAkgt&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Enhancing LLM's Ability to Generate More Repository-Aware Unit Tests Through Precise Context Injection", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "X Yin, C Ni, X Li, L Chen, G Ma, X Yang\nRecently, Large Language Models (LLMs) have gained attention for their ability to \nhandle a broad range of tasks, including unit test generation. Despite their success, \nLLMs may exhibit hallucinations when generating unit tests for focal methods or", "link": "https://scholar.google.com/scholar_url?url=https://vinci-grape.github.io/papers/Enhancing_LLM_s_Ability_to_Generate_More_Repository_Aware_Unit_Tests_Through_Precise_Context_Injection.pdf&hl=vi&sa=X&d=3506872574868649515&ei=GP3_aPjGINWY6rQPrbXRgQY&scisig=ABGrvjKPA0zq2FXS1WyPoCr65qwT&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Real-VulLLM: An LLM Based Assessment Framework in the Wild", "first_label": ["LLM"], "second_label": [], "data": "R Safdar, D Mateen, ST Ali, W Hussain- arXiv preprint arXiv:2510.04056, 2025\nArtificial Intelligence (AI) and more specifically Large Language Models (LLMs) have \ndemonstrated exceptional progress in multiple areas including software engineering, \nhowever, their capability for vulnerability detection in the wild scenario and its", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04056&hl=vi&sa=X&d=7464868966945655593&ei=GP3_aPjGINWY6rQPrbXRgQY&scisig=ABGrvjIaO4pEKfAZ4-It9iNMVajB&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=7&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "The Richer Representation Fallacy: Are We Just Adding Noise to LLM-based Software Vulnerability Detectors?", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "H Hanif, S Maffeis, NB Anuar\nLarge Language Models (LLMs) have established strong baselines for software \nvulnerability detection, leading to a common assumption that their performance can \nbe enhanced by augmenting them with supplementary information such as Abstract", "link": "https://scholar.google.com/scholar_url?url=https://www.doc.ic.ac.uk/~maffeis/papers/icoco25.pdf&hl=vi&sa=X&d=9374945953362351896&ei=GP3_aPjGINWY6rQPrbXRgQY&scisig=ABGrvjJP7g6ze4j15IMQXWKX48ED&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=8&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "IT project infrastructure setup automation with help of large language models", "first_label": ["LLM"], "second_label": [], "data": "VA Ivlev, IV Nikiforov, SM Ustinov- Computing, Telecommunication and Control, 2025\nThis study conducts an analysis of existing large language models (LLMs) and AI \nagents, identifying Llama 2 as the most suitable model for automating IT project \nenvironment configuration. A mathematical model of the proposed method is\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://infocom.spbstu.ru/userfiles/files/articles/2025/2/74-90.pdf&hl=vi&sa=X&d=8794046321267415771&ei=GP3_aPjGINWY6rQPrbXRgQY&scisig=ABGrvjLemX1zaSQ4K09Gbc4ROV8O&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=9&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "MAVUL: Multi-Agent Vulnerability Detection via Contextual Reasoning and Interactive Refinement", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Agent", "Reasoning"], "data": "Y Li, K Joshi, X Wang, E Wong- arXiv preprint arXiv:2510.00317, 2025\nThe widespread adoption of open-source software (OSS) necessitates the mitigation \nof vulnerability risks. Most vulnerability detection (VD) methods are limited by \ninadequate contextual understanding, restrictive single-round interactions, and", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.00317&hl=vi&sa=X&d=577185325914480253&ei=cnz-aJXWDNyOieoP1t-zoQM&scisig=ABGrvjIbyn7OuStXpJ3sqMy4JVsK&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Towards Human-interpretable Explanation in Code Clone Detection using LLM-based Post Hoc Explainer", "first_label": ["LLM", "Code"], "second_label": ["Detection"], "data": "T Racharak, C Ragkhitwetsagul, C Junplong- arXiv preprint arXiv, 2025\nRecent studies highlight various machine learning (ML)-based techniques for code \nclone detection, which can be integrated into developer tools such as static code \nanalysis. With the advancements brought by ML in code understanding, ML-based", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.22978&hl=vi&sa=X&d=13116222657243354012&ei=cnz-aJXWDNyOieoP1t-zoQM&scisig=ABGrvjLcsdvC_Wkq4bjALj1X_8xA&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Source Code Guardrail: AI Driven Solution to Distinguish Critical vs. Generic Code for Enterprise LLM Security", "first_label": ["LLM", "Code"], "second_label": [], "data": "R Sharma, A Gupta- International Conference on Provable Security, 2025\nAbstract The adoption of Large Language Models (LLMs) in businesses raises the \npossibility of inadvertent intellectual property (IP) and secret data leaks to public \nartificial intelligence systems. Organizations are using security solutions, including", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-95-2961-2_23&hl=vi&sa=X&d=5184326828152072441&ei=cnz-aJXWDNyOieoP1t-zoQM&scisig=ABGrvjJOJG-OQ4wH-x-OhS5wRNe2&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "That's Deprecated! Understanding, Detecting, and Steering Knowledge Conflicts in Language Models for Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Detection", "Generation"], "data": "J Bae, C Churchwell, M Hermon, TA Hsieh, J Xu- arXiv preprint arXiv, 2025\nThis paper investigates how large language models (LLMs) behave when faced with \ndiscrepancies between their parametric knowledge and conflicting information \ncontained in a prompt. Building on prior question-answering (QA) research, we", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.19116&hl=vi&sa=X&d=17901384243922605770&ei=cnz-aJXWDNyOieoP1t-zoQM&scisig=ABGrvjLZVf3VGVMR0WZAkCggQrBj&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Local Agentic RAG-Based Information System Development for Intelligent Analysis of GitHub Code Repositories in Computer Science Education", "first_label": ["Code"], "second_label": ["Agent"], "data": "Z Hu, MM Paprotskyi, V Vysotska, L Chyrun, Y Ushenko\nThis study presents the development and evaluation of a local agent-based Retrieval-\nAugmented Generation (Agentic RAG) system designed for the intelligent analysis of \nGitHub repositories in computer science education and IT practice. The novelty of", "link": "https://scholar.google.com/scholar_url?url=https://www.mecs-press.org/ijmecs/ijmecs-v17-n5/IJMECS-V17-N5-7.pdf&hl=vi&sa=X&d=15899062735032558573&ei=cnz-aJXWDNyOieoP1t-zoQM&scisig=ABGrvjIz9ZvXb18eqWpoqNMeLmro&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "TIT: A Tree-Structured Instruction Tuning Approach for LLM-Based Code Translation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "H Jiang, Y Wang, H Lin, P Zou, Z Zhou, A Jia, X Li- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) have shown strong performance in automated \nsource-to-target code translation through pretraining on extensive code corpora. \nHowever, mainstream LLM-based code translation methods suffer from two critical", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.09400&hl=vi&sa=X&d=13736189209612319180&ei=cnz-aJXWDNyOieoP1t-zoQM&scisig=ABGrvjLfQpVO1yEU3BC2VHg0FKp1&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "MirrorFuzz: Leveraging LLM and Shared Bugs for Deep Learning Framework APIs Fuzzing", "first_label": ["LLM", "Fuzzing", "Bug"], "second_label": [], "data": "S Ou, Y Li, L Yu, C Wei, T Wen, Q Chen, Y Chen- IEEE Transactions on, 2025\nDeep learning (DL) frameworks serve as the backbone for a wide range of artificial \nintelligence applications. However, bugs within DL frameworks can cascade into \ncritical issues in higher-level applications, jeopardizing reliability and security. While", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/32/4359463/11201027.pdf&hl=vi&sa=X&d=1422528139240657868&ei=cnz-aJXWDNyOieoP1t-zoQM&scisig=ABGrvjI1tTlw2XwsJvzcyylBVxMq&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "GenDetect: Generative Large Language Model Usage in Smart Contract Vulnerability Detection", "first_label": ["Vulnerabilities", "Smart Contracts", "LLM"], "second_label": ["Detection"], "data": "P Ince, J Yu, JK Liu, X Du, X Luo- International Conference on Provable Security, 2025\nThe last 18 months have seen an explosion of activity in both industry and research \nin the Generative AI space, specifically Large Language Models (LLMs). Smart \ncontract vulnerability detection is no exception; as smart contracts exist on public", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-95-2961-2_22&hl=vi&sa=X&d=11789653647626691564&ei=cnz-aJXWDNyOieoP1t-zoQM&scisig=ABGrvjLKF8la5kBRNxoIkNPsZexT&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=7&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Large Language Models for Code Editing", "first_label": ["LLM", "Code"], "second_label": [], "data": "RJ Mooney, A Shi\nPretrained language models have been shown to be effective in many \nsoftwarerelated generation tasks; however, they are not well-suited for editing tasks \nduring maintaining the software as they are not designed to reason about edits. To\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://users.ece.utexas.edu/~gligoric/papers/Zhang25PhD.pdf&hl=vi&sa=X&d=10229569576199033599&ei=cnz-aJXWDNyOieoP1t-zoQM&scisig=ABGrvjLpWoTa-j_SG0xO2_Fs3G5S&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=8&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Rapid G-CodingObtaining G-code Using AI", "first_label": ["Code"], "second_label": [], "data": "D Tiro- IOP Conference Series: Materials Science and, 2025\nThe traditional process of creating G-code is time-intensive and requires expertise in \nCNC programming. Recently, several AI software have appeared. They \ncommunicate using prompts, and the user can also provide a drawing, which the AI \nprocesses. AI software, such as ChatGPT, Bing AI Copilot, became publicly available \napproximately two years ago. The question arises whether G-code can be obtained \nusing these software. A review of the literature confirmed that no studies have\nTrch dn: Refining chatgpt-generated code: Characterizing and mitigating\u00a0\u00a0\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng li trch dn mi trong cc bi vit ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://iopscience.iop.org/article/10.1088/1757-899X/1339/1/012014/pdf&hl=vi&sa=X&d=9058890831364105878&ei=cnz-aJ7sGM-F6rQPotzKiQ0&scisig=ABGrvjJZdkbjbA92PQw1DWWsR0yb&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:ABGrvjL2eoLgrMchC3yPzCtO9Gb4&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["1 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
