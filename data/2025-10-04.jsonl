{"title": "What Do They Fix? LLM-Aided Categorization of Security Patches for Critical Memory Bugs", "first_label": ["LLM", "Bug"], "second_label": [], "data": "X Li, J Pu, Y Wu, X Zou, S Zhu, Q Wu, Z Zhang, J Hsu- arXiv preprint arXiv, 2025\nOpen-source software projects are foundational to modern software ecosystems, with \nthe Linux kernel standing out as a critical exemplar due to its ubiquity and \ncomplexity. Although security patches are continuously integrated into the Linux", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.22796&hl=vi&sa=X&d=5877456260761011502&ei=7m_faLjrDq3M6rQPuqaCiA0&scisig=AAZF9b_K5bVx20Ft-L-epPjLrGqv&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Adversarial Bug Reports as a Security Risk in Language Model-Based Automated Program Repair", "first_label": ["APR", "LLM", "Bug"], "second_label": ["Repair"], "data": "P Przymus, A Happe, J Cito- arXiv preprint arXiv:2509.05372, 2025\nLarge Language Model (LLM)-based Automated Program Repair (APR) systems are \nincreasingly integrated into modern software development workflows, offering \nautomated patches in response to natural language bug reports. However, this", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.05372&hl=vi&sa=X&d=17856431439942945890&ei=7m_faLjrDq3M6rQPuqaCiA0&scisig=AAZF9b9iNtxXJTJlEQXG_3JYQbs1&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Rethinking Kernel Program Repair: Benchmarking and Enhancing LLMs with RGym", "first_label": ["APR", "LLM"], "second_label": ["Repair"], "data": "K Shehada, Y Wu, WD Feng, A Iyer, G Kumfert, Y Ding- NeurIPS 2025 Workshop on\nLarge Language Models (LLMs) have revolutionized automated program repair \n(APR) but current benchmarks like SWE-Bench predominantly focus on userspace \napplications and overlook the complexities of kernel-space debugging and repair", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DNY4wv5C39G&hl=vi&sa=X&d=13284020585308537468&ei=7m_faLjrDq3M6rQPuqaCiA0&scisig=AAZF9b8qiQW2WOt5dhxoK0fl5lFh&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "When Code Crosses Borders: A Security-Centric Evaluation of LLM-based Code Translation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "H Chang, G Meng, S Xiao, K Chen, K Sun, Y Li- arXiv preprint arXiv:2509.06504, 2025\nWith the growing demand for cross-language codebase migration, evaluating LLMs' \nsecurity implications in translation tasks has become critical. Existing evaluations \nprimarily focus on syntactic or functional correctness at the function level, neglecting", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.06504&hl=vi&sa=X&d=15964686870607645440&ei=7m_faLjrDq3M6rQPuqaCiA0&scisig=AAZF9b9rJmR42d8IPErh15fFE3f8&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "DeepCodeProbe: Evaluating Code Representation Quality in Models Trained on Code", "first_label": ["Code"], "second_label": [], "data": "V Majdinasab, A Nikanjam, F Khomh- Empirical Software Engineering, 2025\nAbstract Machine Learning models trained on code and artifacts extracted from them \n(eg, version control histories, code differences, etc.), provide invaluable assistance \nfor software engineering tasks. Despite their good performance, there exists a lack of", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10664-025-10731-0&hl=vi&sa=X&d=4894546859526238222&ei=7m_faLjrDq3M6rQPuqaCiA0&scisig=AAZF9b9PrlAWMKjBTBOwWDVqSOtc&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Bridging Developer Instructions and Code Completion Through Instruction-Aware Fill-in-the-Middle Paradigm", "first_label": ["Code"], "second_label": ["Generation"], "data": "Z Sun, C Yang, C Peng, P Gao, X Du, L Li, D Lo- arXiv preprint arXiv:2509.24637, 2025\nLarge Language Models (LLMs) have significantly advanced code completion, yet \nthey often fail when the developer's intent is underspecified in the code context. To \naddress this, developers usually add natural language instructions (eg, comments)", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.24637&hl=vi&sa=X&d=17305794744039020422&ei=7m_faLjrDq3M6rQPuqaCiA0&scisig=AAZF9b-qDU6QAC4PPz9qG-_owbNR&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "From Cryptic to Clear-Training on LLM Explanations to Detect Smart Contract Vulnerabilities", "first_label": ["Vulnerabilities", "Smart Contracts", "LLM"], "second_label": [], "data": "Y Chen, Z Sun, G Wang, Q Liang, X Yu, D Hao- ACM Transactions on Software, 2025\nSmart contracts have revolutionized the way transactions are executed, offering \ndecentralized and immutable frameworks. The immutability of smart contracts poses \nsignificant risks when vulnerabilities exist in their code, leading to financial losses", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3765753&hl=vi&sa=X&d=10696251976758637118&ei=7m_faLjrDq3M6rQPuqaCiA0&scisig=AAZF9b9ZBf4NQYTpgMU9yATSPdqf&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Improving the Efficiency of LLM Agent Systems through Trajectory Reduction", "first_label": ["LLM"], "second_label": ["Agent"], "data": "YA Xiao, P Gao, C Peng, Y Xiong- arXiv preprint arXiv:2509.23586, 2025\nMulti-turn agent systems based on Large Language Models (LLMs) have been \nincreasingly popular for software engineering tasks. While LLM agents show decent \neffectiveness, the high computational cost of input tokens due to the ever-growing", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23586&hl=vi&sa=X&d=12596444921036280365&ei=7m_faLjrDq3M6rQPuqaCiA0&scisig=AAZF9b-Nsxb9BzRYoIftNViBPFg1&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=7&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Towards Human-interpretable Explanation in Code Clone Detection using LLM-based Post Hoc Explainer", "first_label": ["LLM", "Code"], "second_label": ["Detection"], "data": "T Racharak, C Ragkhitwetsagul, C Junplong- arXiv preprint arXiv, 2025\nRecent studies highlight various machine learning (ML)-based techniques for code \nclone detection, which can be integrated into developer tools such as static code \nanalysis. With the advancements brought by ML in code understanding, ML-based", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.22978&hl=vi&sa=X&d=13116222657243354012&ei=7m_faLjrDq3M6rQPuqaCiA0&scisig=AAZF9b-CrNTuw-vA-xt9R-PWj2rN&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=8&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "GTVD: a multi-level aggregation vulnerability detection method based on full-dependency program graph", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Graph"], "data": "H He, S Li, Y Li, Y Li- Cluster Computing, 2025\nIn modern software development life cycles, proactive vulnerability discovery and \nremediation play crucial roles in ensuring application security. However, current \ndeep learning-based vulnerability detection methods frequently face limitations due\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10586-025-05506-7&hl=vi&sa=X&d=9365356712912853263&ei=7m_faLjrDq3M6rQPuqaCiA0&scisig=AAZF9b_DdZ4fyL1mLj90wo4wpBRq&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=9&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "TF-Bench: Evaluating Program Semantics Reasoning with Type Inference in System F", "first_label": [], "second_label": ["Reasoning"], "data": "Y He, L Yang, CCG Gonzalo, H Chen- arXiv preprint arXiv:2509.23686, 2025\nLarge Language Models (LLMs) are increasingly integrated into the software \nengineering ecosystem. Their test-time compute (TTC) reasoning capabilities show \nsignificant potential for understanding program logic and semantics beyond mere \ntoken recognition. However, current benchmarks for code reasoning lack a formal, \nprogram-centric deductive framework to ensure sound evaluation, and are incapable \nof assessing whether models genuinely reason about program semantics or merely\nTrch dn: Can LLMs Reason About Program Semantics? A Comprehensive", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23686&hl=vi&sa=X&d=7812027363893781818&ei=7m_faKzQH56sieoP2PTggQg&scisig=AAZF9b921YNdLGMQG7M6UBXqYA2i&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:AAZF9b-KfaIzNELg_AxYHyYLV6lH&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["4 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "HFuzzer: Testing Large Language Models for Package Hallucinations via Phrase-based Fuzzing", "first_label": ["LLM", "Fuzzing", "Software Testing"], "second_label": [], "data": "Y Zhao, M Wu, X Hu, X Xia- arXiv preprint arXiv:2509.23835, 2025\nLarge Language Models (LLMs) are widely used for code generation, but they face \ncritical security risks when applied to practical production due to package \nhallucinations, in which LLMs recommend non-existent packages. These \nhallucinations can be exploited in software supply chain attacks, where malicious \nattackers exploit them to register harmful packages. It is critical to test LLMs for \npackage hallucinations to mitigate package hallucinations and defend against\nTrch dn: Refining chatgpt-generated code: Characterizing and mitigating", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23835&hl=vi&sa=X&d=16917587561815760773&ei=7m_faKzQH56sieoP2PTggQg&scisig=AAZF9b8Mk-rnOTcKAAGqO9tIlO4J&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:AAZF9b-KfaIzNELg_AxYHyYLV6lH&html=&pos=1&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["4 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "Automated Vulnerability Validation and Verification: A Large Language Model Approach", "first_label": ["Vulnerabilities", "Verification", "LLM"], "second_label": [], "data": "A Lotfi, C Katsis, E Bertino- arXiv preprint arXiv:2509.24037, 2025\nSoftware vulnerabilities remain a critical security challenge, providing entry points for \nattackers into enterprise networks. Despite advances in security practices, the lack of \nhigh-quality datasets capturing diverse exploit behavior limits effective vulnerability \nassessment and mitigation. This paper introduces an end-to-end multi-step pipeline \nleveraging generative AI, specifically large language models (LLMs), to address the \nchallenges of orchestrating and reproducing attacks to known software\nTrch dn: Refining chatgpt-generated code: Characterizing and mitigating", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.24037&hl=vi&sa=X&d=7978409907240033186&ei=7m_faKzQH56sieoP2PTggQg&scisig=AAZF9b8QoVaounWNCXofucwywvLP&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:AAZF9b-KfaIzNELg_AxYHyYLV6lH&html=&pos=2&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["4 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "Metamorphic Testing of Deep Code Models: A Systematic", "first_label": ["Code", "Software Testing"], "second_label": [], "data": "ALI ASGARI, M DE KONING, P DERAKHSHANFAR - 2025\nIn recent years, large language models for code (LLM4Code) have achieved \nremarkable performance across a range of software engineering tasks, reaching \naccuracy levels that make them increasingly viable for real-world adoption. These \ntasks include, but are not limited to, program repair [1], vulnerability detection [2, 3], \ncode completion [4, 5], and clone detection [6, 7], among others. However, the \npractical applicability of LLM4Code depends not only on their performance on\nTrch dn: Evaluating program repair with semantic-preserving\u00a0\u00a0\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng li trch dn mi trong cc bi vit ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Annibale-Panichella/publication/395486459_Metamorphic_Testing_of_Deep_Code_Models_A_Systematic_Literature_Review/links/68d12186220a341aa14e4b74/Metamorphic-Testing-of-Deep-Code-Models-A-Systematic-Literature-Review.pdf&hl=vi&sa=X&d=4283050785129156787&ei=7m_faKzQH56sieoP2PTggQg&scisig=AAZF9b8CPVZTSsxHUaaieQPV0b6M&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:AAZF9b-KfaIzNELg_AxYHyYLV6lH&html=&pos=3&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["4 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
