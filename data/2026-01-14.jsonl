{"title": "Reporting LLM Prompting in Automated Software Engineering: A Guideline Based on Current Practices and Expectations", "first_label": ["LLM"], "second_label": [], "data": "A Korn, L Zaruchas, C Arora, A Metzger, S Smolka- arXiv preprint arXiv, 2026\nLarge Language Models, particularly decoder-only generative models such as GPT, \nare increasingly used to automate Software Engineering tasks. These models are \nprimarily guided through natural language prompts, making prompt engineering a\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.01954&hl=vi&sa=X&d=4332027767690105897&ei=RVNmaea8KMyQieoPoq-Z8AE&scisig=AHkA5jRKYibitBJSa1-RX89FLKon&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AHkA5jQSH2z-ynDQhPp_cW7HGs_g&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Advancing Language Models for Code-related Tasks", "first_label": ["LLM", "Code"], "second_label": [], "data": "Z Tian- arXiv preprint arXiv:2601.04526, 2026\nRecent advances in language models (LMs) have driven significant progress in \nvarious software engineering tasks. However, existing LMs still struggle with complex \nprogramming scenarios due to limitations in data quality, model architecture, and", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.04526&hl=vi&sa=X&d=764230178145390917&ei=jqJkaYLgNtrJieoPiYyysAk&scisig=AHkA5jRnXe6mlpjQZHCb4gJPiztq&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AHkA5jQSH2z-ynDQhPp_cW7HGs_g&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Sphinx: Benchmarking and Modeling for LLM-Driven Pull Request Review", "first_label": ["LLM"], "second_label": [], "data": "D Zhang, S Zhang, Z Jin, J Luo, S Fu, E Nallipogu- arXiv preprint arXiv:2601.04252, 2026\nPull request (PR) review is essential for ensuring software quality, yet automating this \ntask remains challenging due to noisy supervision, limited contextual understanding, \nand inadequate evaluation metrics. We present Sphinx, a unified framework for LLM\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.04252&hl=vi&sa=X&d=17254889004773618053&ei=jqJkaYLgNtrJieoPiYyysAk&scisig=AHkA5jRPeMWbBk53LB8KhQ9zdwzs&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AHkA5jQSH2z-ynDQhPp_cW7HGs_g&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "AI-assisted code generation tools: a new frontier in software development", "first_label": ["Code"], "second_label": ["Generation"], "data": "ZM Nabi, I Jaman, U Bose, TT Hossain, D Kamal - 2025\nThrough various developments in Artificial Intelligence code generation, it has \ngreatly influenced the development of codebases and software. This has increased \nefficiency and led to the development of conventional programs and practices. This \nthesis emphasises these AI tools and their impact on the developer's experience in \nreal-world applications, and also addresses critical gaps in the existing literature. \nThrough thorough analysis, this paper demonstrates that AI code generation can\nTrch dn: Refining chatgpt-generated code: Characterizing and mitigating", "link": "https://scholar.google.com/scholar_url?url=https://dspace.bracu.ac.bd:8443/xmlui/bitstream/handle/10361/27410/23241120%252C%252024141204%252C%252021201782%252C%252023241123%252C%252021201458_CSE.pdf%3Fsequence%3D1%26isAllowed%3Dy&hl=vi&sa=X&d=6763488893250814459&ei=j6Jkaf_RBcelieoP1s_TgA8&scisig=AHkA5jSTqC3joAYqavNO5YofzREA&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:AHkA5jTPS8thqNJxu8pHnPo4odW8&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["2 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "A Novel Multi-scale Graph Neural Network Architecture for Enhanced Performance on Heterogeneous Data", "first_label": [], "second_label": ["Graph"], "data": "B Geetha, AR Masoom Basha Pinjari, SV Krushna- Amit Kumar Gheorghita Ghinea\nGraph neural networks (GNNs) are powerful models that work on graphstructured \ndata and have been widely used in multiple applications, including network \nneuroscience tasks, bioinformatics tasks, power systems scenarios, and social \nnetwork research. Although successful, most existing GNN models still need to \naccurately model multi-scale information across graphs with different scales \n(abstraction levels), consequently weakening their generalization ability on\nTrch dn: Toward the Analysis of Graph Neural Network\u00a0\u00a0\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng li trch dn mi trong cc bi vit ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/content/pdf/10.1007/978-981-95-0140-3.pdf%23page%3D197&hl=vi&sa=X&d=17821876204074492896&ei=j6Jkaf_RBcelieoP1s_TgA8&scisig=AHkA5jTM4jeN0MpW9KfMYqTqSmxk&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:AHkA5jTPS8thqNJxu8pHnPo4odW8&html=&pos=1&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["2 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
