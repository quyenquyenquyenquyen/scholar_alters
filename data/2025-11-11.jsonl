{"title": "Collaborative Agents for Automated Program Repair in Ruby", "first_label": ["APR"], "second_label": ["Repair", "Agent"], "data": "N Akbarpour, MS Benis, FH Fard, A Ouni, MA Saied- arXiv preprint arXiv:2511.03925, 2025\nAutomated Program Repair (APR) has advanced rapidly with Large Language \nModels (LLMs), but most existing methods remain computationally expensive, and \nfocused on a small set of languages. Ruby, despite its widespread use in web", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.03925&hl=vi&sa=X&d=7133608131634426271&ei=Xv0RafW3G4S6ieoP-o_w-Qg&scisig=ABGrvjLMaPVI6DKbVF3rUl_tJgdF&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Beyond SWE-Bench: A Compiler-Assisted Pipeline for Multi-language Automated Program Repair", "first_label": ["APR"], "second_label": ["Repair"], "data": "M Pineda, D Luna, M Esquivel, J Bours, J Salazar- International Conference on, 2025\nAutomated program repair (APR) research predominantly focuses on Python \nenvironments, creating significant infrastructure gaps for compiled languages like C, \nC++, and Java that dominate production systems. We present the first systematic", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-032-09044-7_9&hl=vi&sa=X&d=9652754918189750732&ei=Xv0RafW3G4S6ieoP-o_w-Qg&scisig=ABGrvjLsQlCCYsmwCJRV6mzSR0Rl&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "A Program Synthesis Dataset for LLM Temperature Analysis", "first_label": ["LLM"], "second_label": [], "data": "Z Sgodi, I Kollth, P Hegeds, R Ferenc- IEEE Access, 2025\nLarge Language Models (LLMs) play an increasingly critical role in software \nengineering research, aiding tasks such as program synthesis, automated program \nrepair, and test case generation. While extensive evaluations of LLMs exist, those", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/6514899/11216419.pdf&hl=vi&sa=X&d=15789985321447297160&ei=Xv0RafW3G4S6ieoP-o_w-Qg&scisig=ABGrvjLNewKPXm6mo80GjqlQ2E8O&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Leveraging Intra-and Inter-References in vulnerability detection using Multi-Agent collaboration based on LLMs", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection", "Agent"], "data": "CN Tsai, J Xie, CM Lai, CS Lin- Cluster Computing, 2025\nAs AI technology advances, early detection of code vulnerabilities becomes \nincreasingly critical for preventing exploitation, reducing remediation costs, \nenhancing user trust, and improving system performance. Recently, Large language", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10586-025-05721-2&hl=vi&sa=X&d=10835680397604577360&ei=Xv0RafW3G4S6ieoP-o_w-Qg&scisig=ABGrvjLvup8kWfy-ji1NVhu3K4zl&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "EDIT-Bench: Evaluating LLM Abilities to Perform Real-World Instructed Code Edits", "first_label": ["LLM", "Code"], "second_label": [], "data": "W Chi, V Chen, R Shar, A Mittal, J Liang, WL Chiang- arXiv preprint arXiv, 2025\nInstructed code editing, where LLMs directly modify a developer's existing code \nbased on a user instruction, is becoming a widely used interaction mode in AI coding \nassistants. However, few benchmarks directly evaluate this capability and current", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.04486&hl=vi&sa=X&d=5283698315003684171&ei=Xv0RafW3G4S6ieoP-o_w-Qg&scisig=ABGrvjKwOFDZztr52wE5TC4Cj2cm&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "MonoEmbed: Enhancing LLM representations for monolith to microservices decomposition through contrastive learning", "first_label": ["LLM"], "second_label": [], "data": "K Sellami, MA Saied- Empirical Software Engineering, 2026\nAs Monolithic applications evolve, they become increasingly difficult to maintain and \nimprove, leading to scaling and organizational issues. The Microservices \narchitecture, known for its modularity, flexibility and scalability, offers a solution for", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10664-025-10732-z&hl=vi&sa=X&d=8063920521906541806&ei=Xv0RafW3G4S6ieoP-o_w-Qg&scisig=ABGrvjLmQRs92VLTYJdMXzRogB81&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "An Experimental Study of Real-Life LLM-Proposed Performance Improvements", "first_label": ["LLM"], "second_label": [], "data": "L Yi, G Gay, P Leitner- arXiv preprint arXiv:2510.15494, 2025\nLarge Language Models (LLMs) can generate code, but can they generate fast \ncode? In this paper, we study this question using a dataset of 65 real-world tasks \nmined from open-source Java programs. We specifically select tasks where", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.15494&hl=vi&sa=X&d=10640118915085146028&ei=Xv0RafW3G4S6ieoP-o_w-Qg&scisig=ABGrvjLcRUj8NSio7-ggPhAhEwVg&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "SemOpt: LLM-Driven Code Optimization via Rule-Based Analysis", "first_label": ["LLM", "Code"], "second_label": [], "data": "Y Zhao, YA Xiao, Q Xiao, Z Zhang, Y Xiong- arXiv preprint arXiv:2510.16384, 2025\nAutomated code optimization aims to improve performance in programs by \nrefactoring code, and recent studies focus on utilizing LLMs for the optimization. \nTypical existing approaches mine optimization commits from open-source", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.16384&hl=vi&sa=X&d=17733183336457524325&ei=Xv0RafW3G4S6ieoP-o_w-Qg&scisig=ABGrvjIdTJLV1wH4Tm1656yfT86T&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=7&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Specification-Guided Vulnerability Detection with Large Language Models", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "H Zhu, J Li, C Gao, J Qian, Y Dong, H Liu, L Wang- arXiv preprint arXiv, 2025\nLarge language models (LLMs) have achieved remarkable progress in code \nunderstanding tasks. However, they demonstrate limited performance in vulnerability \ndetection and struggle to distinguish vulnerable code from patched code. We argue", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.04014&hl=vi&sa=X&d=6903370528801109309&ei=Xv0RafW3G4S6ieoP-o_w-Qg&scisig=ABGrvjIwxBDCapT2CfMPbKMeujAg&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=8&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "IR-OptSet: An Optimization-Sensitive Dataset for Advancing LLM-Based IR Optimizer", "first_label": ["LLM"], "second_label": [], "data": "Z Yang, L Qiu, F Lyu, M Zhong, Z Chai, H Zhou, H Cui- The Thirty-ninth Annual\nCompiler optimization is essential for improving program performance, yet modern \ncompilers still depend on manually crafted transformation rules over intermediate \nrepresentations (IRs). As compilers grow in complexity, maintaining these rule-based\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DU8qonc6dMF&hl=vi&sa=X&d=8385962303449824386&ei=Xv0RafW3G4S6ieoP-o_w-Qg&scisig=ABGrvjIRN94MWkpha-MTknkgoyTG&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=9&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Foundations and Challenges of Multi-Fault Program Repair", "first_label": ["APR"], "second_label": ["Repair"], "data": "OI AL-BATAINEH - 2025\nAutomated Program Repair (APR) has achieved notable success in single-fault \nsettings [16, 27], yet real-world software systems seldom contain only one defect. \nMultiple interacting faults are common, and their presence changes the nature of the", "link": "https://scholar.google.com/scholar_url?url=https://omarbat92.github.io/omar-website/Confpapers/MFAPR.pdf&hl=vi&sa=X&d=9273097594710911547&ei=tJEQac3fKYePieoPuIjpsAQ&scisig=ABGrvjL20GNsyuiqjhZVawla5BPs&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "A zero-shot framework for cross-project vulnerability detection in source code", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection"], "data": "R Haque, A Ali, S McClean, N Khan- Empirical Software Engineering, 2026\nThe growing prevalence of software vulnerabilities has increased the need for \neffective detection methods, particularly in cross-project settings where domain \ndifferences create significant challenges. Existing vulnerability detection models", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10664-025-10749-4&hl=vi&sa=X&d=5787044264909627309&ei=tJEQac3fKYePieoPuIjpsAQ&scisig=ABGrvjJ29zOgzha_sOP3xWytZM2T&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "LMFuzz: Program repair fuzzing based on large language models", "first_label": ["APR", "LLM", "Fuzzing"], "second_label": ["Repair"], "data": "R Lin, R Wang, G Hu, X Xu- Automated Software Engineering, 2026\nGenerating programs using large language models (LLMs) for fuzz testing has \nemerged as a significant testing methodology. While traditional fuzzers can produce \ncorrect programs, their effectiveness is limited by excessive constraints and restricted", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00568-8&hl=vi&sa=X&d=16706984066078411801&ei=tJEQac3fKYePieoPuIjpsAQ&scisig=ABGrvjLMTxGR3-Z1Hr556q7Ejx9K&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "CodeCrash: Exposing LLM Fragility to Misleading Natural Language in Code Reasoning", "first_label": ["LLM", "Code"], "second_label": ["Reasoning"], "data": "MH Lam, C Wang, J Huang, M Lyu- The Thirty-ninth Annual Conference on Neural\nLarge Language Models (LLMs) have recently demonstrated strong capabilities in \ncode-related tasks, but their robustness in code reasoning under perturbations \nremains underexplored. We introduce CodeCrash, a stress-testing framework with", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DCAB0EjD9EK&hl=vi&sa=X&d=13889957657119136301&ei=tJEQac3fKYePieoPuIjpsAQ&scisig=ABGrvjLDDoY0GiXO7mB3QF7Zpr9h&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Source Code Guardrail: AI Driven Solution to Distinguish Critical vs. Generic Code for Enterprise LLM Security", "first_label": ["LLM", "Code"], "second_label": [], "data": "R Sharma, A Gupta- International Conference on Provable Security, 2025\nAbstract The adoption of Large Language Models (LLMs) in businesses raises the \npossibility of inadvertent intellectual property (IP) and secret data leaks to public \nartificial intelligence systems. Organizations are using security solutions, including", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-95-2961-2_23&hl=vi&sa=X&d=5184326828152072441&ei=tJEQac3fKYePieoPuIjpsAQ&scisig=ABGrvjJOJG-OQ4wH-x-OhS5wRNe2&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Exploring Data-Efficient Adaptation of Large Language Models for Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "X Jiang, Y Dong, Z Fan, Z Jin, W Jiao, G Li- ACM Transactions on Software, 2025\nAlthough Large Language Models (LLMs) have made significant progress in code \ngeneration, they still struggle with code generation tasks in specific scenarios. These \nscenarios usually necessitate the adaptation of LLMs to fulfill specific needs, but the", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3772721&hl=vi&sa=X&d=2686921242856750605&ei=tJEQac3fKYePieoPuIjpsAQ&scisig=ABGrvjI_8WoaFiP253fyOzGjNdkw&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Preconditions and Postconditions as Design Constraints for LLM Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "L Newcomb, A Davidoff, O Ochoa- IEEE Access, 2025\nLarge Language Models (LLMs) have significantly advanced automated code \ngeneration, but current methods predominantly rely on natural language descriptions \nduring prompting. This approach encounters challenges when handling complex", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/6514899/11218044.pdf&hl=vi&sa=X&d=2337714649732748995&ei=tJEQac3fKYePieoPuIjpsAQ&scisig=ABGrvjKSLf-Xyz3bwoDp_ol_ElmA&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "MirrorFuzz: Leveraging LLM and Shared Bugs for Deep Learning Framework APIs Fuzzing", "first_label": ["LLM", "Fuzzing", "Bug"], "second_label": [], "data": "S Ou, Y Li, L Yu, C Wei, T Wen, Q Chen, Y Chen- IEEE Transactions on, 2025\nDeep learning (DL) frameworks serve as the backbone for a wide range of artificial \nintelligence applications. However, bugs within DL frameworks can cascade into \ncritical issues in higher-level applications, jeopardizing reliability and security. While", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/32/4359463/11201027.pdf&hl=vi&sa=X&d=1422528139240657868&ei=tJEQac3fKYePieoPuIjpsAQ&scisig=ABGrvjI1tTlw2XwsJvzcyylBVxMq&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=7&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "TIT: A Tree-Structured Instruction Tuning Approach for LLM-Based Code Translation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "H Jiang, Y Wang, H Lin, P Zou, Z Zhou, A Jia, X Li- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) have shown strong performance in automated \nsource-to-target code translation through pretraining on extensive code corpora. \nHowever, mainstream LLM-based code translation methods suffer from two critical", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.09400&hl=vi&sa=X&d=13736189209612319180&ei=tJEQac3fKYePieoPuIjpsAQ&scisig=ABGrvjLfQpVO1yEU3BC2VHg0FKp1&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=8&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Adaptive Proof Refinement with LLM-Guided Strategy Selection", "first_label": ["LLM"], "second_label": [], "data": "M Lu, Z Zhou, D Xie, S Jia, B Delaware, T Zhang- arXiv preprint arXiv:2510.25103, 2025\nFormal verification via theorem proving enables the expressive specification and \nrigorous proof of software correctness, but it is difficult to scale due to the significant \nmanual effort and expertise required. While Large Language Models (LLMs) show\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.25103&hl=vi&sa=X&d=5975204416659974907&ei=tJEQac3fKYePieoPuIjpsAQ&scisig=ABGrvjKkxpZfzPdYuZ4UtGP1F_PP&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=9&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
