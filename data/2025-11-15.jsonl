{"title": "An Empirical Study of Java Code Improvements Based on Stack Overflow Answer Edits", "first_label": ["Code"], "second_label": [], "data": "I Wiratsin, C Ragkhitwetsagul, M Paixao, D De Sousa- arXiv preprint arXiv, 2025\nSuboptimal code is prevalent in software systems. Developers often write low-quality \ncode due to factors like technical knowledge gaps, insufficient experience, time \npressure, management decisions, or personal factors. Once integrated, the \naccumulation of this suboptimal code leads to significant maintenance costs and \ntechnical debt. Developers frequently consult external knowledge bases, such as API \ndocumentation and Q&A websites like Stack Overflow (SO), to aid their programming\nTrch dn: Refining chatgpt-generated code: Characterizing and mitigating\u00a0\u00a0\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng li trch dn mi trong cc bi vit ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.05813&hl=vi&sa=X&d=14288274367252986419&ei=_WUWaeK4DP-j6rQP4bnfgAk&scisig=ABGrvjJYbzkdAMptKeoEPRcnRup2&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:ABGrvjL2eoLgrMchC3yPzCtO9Gb4&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["1 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "MENTOR: Fixing Introductory Programming Assignments With Formula-Based Fault Localization and LLM-Driven Program Repair", "first_label": ["APR", "LLM", "Fault Localization"], "second_label": ["Repair", "Localization"], "data": "P Orvalho, M Janota, V Manquinho- Journal of Systems and Software, 2025\nThe increasing demand for programming education has led to online evaluations like \nMOOCs, which rely on introductory programming assignments (IPAs). A major \nchallenge in these courses is providing personalized feedback at scale. This paper", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225003590&hl=vi&sa=X&d=10317565379265188835&ei=_WUWaaZ4zaPqtA_N2b3ZAw&scisig=ABGrvjIWSOda_iCbhMOCF6Bvu9Pz&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "A zero-shot framework for cross-project vulnerability detection in source code", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection"], "data": "R Haque, A Ali, S McClean, N Khan- Empirical Software Engineering, 2026\nThe growing prevalence of software vulnerabilities has increased the need for \neffective detection methods, particularly in cross-project settings where domain \ndifferences create significant challenges. Existing vulnerability detection models", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10664-025-10749-4&hl=vi&sa=X&d=5787044264909627309&ei=_WUWaaZ4zaPqtA_N2b3ZAw&scisig=ABGrvjJ29zOgzha_sOP3xWytZM2T&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "A Metamorphic Testing Perspective on Knowledge Distillation for Language Models of Code: Does the Student Deeply Mimic the Teacher?", "first_label": ["LLM", "Code", "Software Testing"], "second_label": [], "data": "MA Awal, M Rochan, CK Roy- arXiv preprint arXiv:2511.05476, 2025\nTransformer-based language models of code have achieved state-of-the-art \nperformance across a wide range of software analytics tasks, but their practical \ndeployment remains limited due to high computational costs, slow inference speeds", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.05476&hl=vi&sa=X&d=696254596676747652&ei=_WUWaaZ4zaPqtA_N2b3ZAw&scisig=ABGrvjK_Q2aL1u4_vrBbTDSTX8GZ&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Hidden Backdoor Attack against Neural Code Search Models", "first_label": ["Code"], "second_label": ["Search"], "data": "Y Chen, W Sun, C Fang, Q Zhang, Z Chen, X Zhang- ACM Transactions on Software, 2025\nReusing off-the-shelf code snippets from online repositories is a common practice, \nwhich significantly enhances the productivity of software developers. To find desired \ncode snippets, developers resort to code search engines through natural language", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3774421&hl=vi&sa=X&d=14015448197656882741&ei=_WUWaaZ4zaPqtA_N2b3ZAw&scisig=ABGrvjJIw4MMUx1gIphm3P9y0MGJ&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "LMFuzz: Program repair fuzzing based on large language models", "first_label": ["APR", "LLM", "Fuzzing"], "second_label": ["Repair"], "data": "R Lin, R Wang, G Hu, X Xu- Automated Software Engineering, 2026\nGenerating programs using large language models (LLMs) for fuzz testing has \nemerged as a significant testing methodology. While traditional fuzzers can produce \ncorrect programs, their effectiveness is limited by excessive constraints and restricted", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00568-8&hl=vi&sa=X&d=16706984066078411801&ei=_WUWaaZ4zaPqtA_N2b3ZAw&scisig=ABGrvjLMTxGR3-Z1Hr556q7Ejx9K&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Beyond Synthetic Benchmarks: Evaluating LLM Performance on Real-World Class-Level Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "M Rahman, SH Khatoonabadi, E Shihab- arXiv preprint arXiv:2510.26130, 2025\nLarge language models (LLMs) have advanced code generation at the function \nlevel, yet their ability to produce correct class-level implementations in authentic \nsoftware projects remains poorly understood. This work introduces a novel", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.26130&hl=vi&sa=X&d=13761241531887805841&ei=_WUWaaZ4zaPqtA_N2b3ZAw&scisig=ABGrvjLlYmn4XLej__SC0XdKrFFY&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "CodeCrash: Exposing LLM Fragility to Misleading Natural Language in Code Reasoning", "first_label": ["LLM", "Code"], "second_label": ["Reasoning"], "data": "MH Lam, C Wang, J Huang, M Lyu- The Thirty-ninth Annual Conference on Neural\nLarge Language Models (LLMs) have recently demonstrated strong capabilities in \ncode-related tasks, but their robustness in code reasoning under perturbations \nremains underexplored. We introduce CodeCrash, a stress-testing framework with", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DCAB0EjD9EK&hl=vi&sa=X&d=13889957657119136301&ei=_WUWaaZ4zaPqtA_N2b3ZAw&scisig=ABGrvjLDDoY0GiXO7mB3QF7Zpr9h&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "SWE-fficiency: Can Language Models Optimize Real-World Repositories on Real Workloads?", "first_label": ["LLM"], "second_label": [], "data": "JJ Ma, M Hashemi, A Yazdanbakhsh, K Swersky- arXiv preprint arXiv, 2025\nOptimizing the performance of large-scale software repositories demands expertise \nin code reasoning and software engineering (SWE) to reduce runtime while \npreserving program correctness. However, most benchmarks emphasize what to fix", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.06090&hl=vi&sa=X&d=13977523712886318552&ei=_WUWaaZ4zaPqtA_N2b3ZAw&scisig=ABGrvjIhBXwrpobE-t7e-F3QUiTO&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=7&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "SecureReviewer: Enhancing Large Language Models for Secure Code Review through Secure-aware Fine-tuning", "first_label": ["LLM", "Code Review", "Code"], "second_label": [], "data": "F Liu, S Liu, Y Zhu, X Lian, L Zhang- arXiv preprint arXiv:2510.26457, 2025\nIdentifying and addressing security issues during the early phase of the development \nlifecycle is critical for mitigating the long-term negative impacts on software systems. \nCode review serves as an effective practice that enables developers to check their", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.26457&hl=vi&sa=X&d=2750772061662092214&ei=_WUWaaZ4zaPqtA_N2b3ZAw&scisig=ABGrvjJCIQLgS8ShLO-ChXzeoUuk&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=8&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Exploring Data-Efficient Adaptation of Large Language Models for Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "X Jiang, Y Dong, Z Fan, Z Jin, W Jiao, G Li- ACM Transactions on Software, 2025\nAlthough Large Language Models (LLMs) have made significant progress in code \ngeneration, they still struggle with code generation tasks in specific scenarios. These \nscenarios usually necessitate the adaptation of LLMs to fulfill specific needs, but the\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3772721&hl=vi&sa=X&d=2686921242856750605&ei=_WUWaaZ4zaPqtA_N2b3ZAw&scisig=ABGrvjI_8WoaFiP253fyOzGjNdkw&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=9&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
