{"title": "Evaluating Large Language Models for Line-Level Vulnerability Localization", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Localization"], "data": "J Zhang, C Wang, A Li, W Sun, C Zhang, W Ma, Y Liu- IEEE Transactions on, 2025\nRecently, Automated Vulnerability Localization (AVL) has attracted growing attention, \naiming to facilitate diagnosis by pinpointing the specific lines of code responsible for \nvulnerabilities. Large Language Models (LLMs) have shown potential in various", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11318142/&hl=vi&sa=X&d=5253556010021438658&ei=uI92ae-AG6Oi6rQPoMCXoAE&scisig=AHkA5jT971lTQQwYnbJwN8erjC8U&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AHkA5jQSH2z-ynDQhPp_cW7HGs_g&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Integrating Attention Mechanism with Code Structural Affinity and Execution Context Correlation for Automated Bug Repair", "first_label": ["Code", "Bug"], "second_label": ["Repair"], "data": "J Ji, G Yang- Computers, Materials and Continua, 2026\nAutomated Program Repair (APR) techniques have shown significant potential in \nmitigating the cost and complexity associated with debugging by automatically \ngenerating corrective patches for software defects. Despite considerable progress in", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/org/science/article/pii/S1546221826000949&hl=vi&sa=X&d=8389963293695928641&ei=uI92ae-AG6Oi6rQPoMCXoAE&scisig=AHkA5jQFm7KEgP1IGLDXktyMDEVn&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AHkA5jQSH2z-ynDQhPp_cW7HGs_g&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "LLM-Based Repair of C++ Implicit Data Loss Compiler Warnings: An Industrial Case Study", "first_label": ["LLM"], "second_label": ["Repair"], "data": "C You, HD Choi, J Hong- arXiv preprint arXiv:2601.14936, 2026\nThis paper presents a method to automatically fix implicit data loss warnings in large \nC++ projects using Large Language Models (LLMs). Our approach uses the \nLanguage Server Protocol (LSP) to gather context, Tree-sitter to extract relevant", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.14936&hl=vi&sa=X&d=5455946562152744833&ei=uI92ae-AG6Oi6rQPoMCXoAE&scisig=AHkA5jSHGm4NfHUzdtOnWkd86BMt&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AHkA5jQSH2z-ynDQhPp_cW7HGs_g&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "A novel method for vulnerability detection based on fusion and hyperbolic neural network graphs", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Graph"], "data": "X Li, A Bhattacharjya, Q Li, MC Zhou, R Wisniewski- IEEE Transactions on, 2026\nDetecting vulnerabilities in source code is essential for maintaining cybersecurity in \ndigital space. Recent research has highlighted the strong representational \ncapabilities of Graph Neural Networks (GNNs) in modeling the structural features of\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11359578/&hl=vi&sa=X&d=1765881927313816104&ei=uI92ae-AG6Oi6rQPoMCXoAE&scisig=AHkA5jSRjZMLG4Coh_QwlG0w4bgj&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AHkA5jQSH2z-ynDQhPp_cW7HGs_g&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "VulnResolver: A Hybrid Agent Framework for LLM-Based Automated Vulnerability Issue Resolution", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Agent"], "data": "M Zhang, X Wang, J Zhang, X Meng, J Zhang, C Hu- arXiv preprint arXiv:2601.13933, 2026\nAs software systems grow in complexity, security vulnerabilities have become \nincreasingly prevalent, posing serious risks and economic costs. Although \nautomated detection tools such as fuzzers have advanced considerably, effective", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.13933&hl=vi&sa=X&d=8029152925504295835&ei=SEB1abrqOPOlieoPkILrwAk&scisig=AHkA5jQmsTzVGlQkTvR3J_8xTI44&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AHkA5jQSH2z-ynDQhPp_cW7HGs_g&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Parameter-Efficient Multi-Task Fine-Tuning in Code-Related Tasks", "first_label": ["Code"], "second_label": [], "data": "MZ Haque, S Afrin, A Mastropaolo- arXiv preprint arXiv:2601.15094, 2026\nLarge Language Models (LLMs) have proven highly effective in automating software \nengineering tasks, bridging natural language and code semantics to achieve notable \nresults in code generation and summarization. However, their scale incurs", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.15094&hl=vi&sa=X&d=8593991838871028005&ei=SEB1abrqOPOlieoPkILrwAk&scisig=AHkA5jQpbz7hVbq2Ge1aNRMeVipU&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AHkA5jQSH2z-ynDQhPp_cW7HGs_g&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi", "3 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "From LLMs to Agents in Programming: The Impact of Providing an LLM with a Compiler", "first_label": ["LLM"], "second_label": ["Agent"], "data": "V Kjellberg, M Staron, F Fotrousi- arXiv preprint arXiv:2601.12146, 2026\nLarge Language Models have demonstrated a remarkable capability in natural \nlanguage and program generation and software development. However, the source \ncode generated by the LLMs does not always meet quality requirements and may fail", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.12146&hl=vi&sa=X&d=11329828215171022159&ei=SEB1abrqOPOlieoPkILrwAk&scisig=AHkA5jQUd6mj6Dh0AMGpbha_Vfxk&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AHkA5jQSH2z-ynDQhPp_cW7HGs_g&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "A Benchmark for Language Models in Real-World System Building", "first_label": ["LLM"], "second_label": [], "data": "W Jin, C Zhao, Z Huang, C Zhang, Q Lin, C Bansal- arXiv preprint arXiv, 2026\nDuring migration across instruction set architectures (ISAs), software package build \nrepair is a critical task for ensuring the reliability of software deployment and the \nstability of modern operating systems. While Large Language Models (LLMs) have", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.12927&hl=vi&sa=X&d=10037879495575465280&ei=SEB1abrqOPOlieoPkILrwAk&scisig=AHkA5jQeIubnmhcW3KaIM8xxFj4x&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AHkA5jQSH2z-ynDQhPp_cW7HGs_g&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Guidelines to Prompt Large Language Models for Code Generation: An Empirical Characterization", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "A Midolo, A Giagnorio, F Zampetti, R Tufano, G Bavota- arXiv preprint arXiv, 2026\nLarge Language Models (LLMs) are nowadays extensively used for various types of \nsoftware engineering tasks, primarily code generation. Previous research has shown \nhow suitable prompt engineering could help developers in improving their code", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.13118&hl=vi&sa=X&d=3872723702867573145&ei=SEB1abrqOPOlieoPkILrwAk&scisig=AHkA5jTVeNrtrIVS16PbNjmm8A_n&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AHkA5jQSH2z-ynDQhPp_cW7HGs_g&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "When Agents Fail: A Comprehensive Study of Bugs in LLM Agents with Automated Labeling", "first_label": ["LLM", "Bug"], "second_label": ["Agent"], "data": "N Islam, RS Ayon, DG Thomas, S Ahmed, M Wardat- arXiv preprint arXiv:2601.15232, 2026\nLarge Language Models (LLMs) have revolutionized intelligent application \ndevelopment. While standalone LLMs cannot perform any actions, LLM agents \naddress the limitation by integrating tools. However, debugging LLM agents is", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.15232&hl=vi&sa=X&d=3478988133296608347&ei=SEB1abrqOPOlieoPkILrwAk&scisig=AHkA5jTiTWCRX7eNkrmmPIiRnSYO&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AHkA5jQSH2z-ynDQhPp_cW7HGs_g&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Discovering 100+ Compiler Defects in 72 Hours via LLM-Driven Semantic Logic Recomposition", "first_label": ["LLM", "Software Defect"], "second_label": [], "data": "X He, Y Chen, H Wu, J Zhang, Z Wang, L Chen, J Peng- arXiv preprint arXiv, 2026\nCompilers constitute the foundational root-of-trust in software supply chains; \nhowever, their immense complexity inevitably conceals critical defects. Recent \nresearch has attempted to leverage historical bugs to design new mutation operators", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.12360&hl=vi&sa=X&d=13422472677440949050&ei=SEB1abrqOPOlieoPkILrwAk&scisig=AHkA5jTh54bePNoEQti1t4QZbrVO&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AHkA5jQSH2z-ynDQhPp_cW7HGs_g&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Promises and Perils of LLM-and Agent-Generated Code", "first_label": ["LLM", "Code"], "second_label": ["Agent"], "data": "PT Devanbu- Computer, 2025\nThis article draws attention to the fact that, traditionally, software maintenance costs \nhave strongly dominated initial development costs, and calls for more in-depth, \nfocused, specialized studies of the actual impacts of large language model-and\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/2/11320986/11321004.pdf&hl=vi&sa=X&d=6472013210972044478&ei=SEB1abrqOPOlieoPkILrwAk&scisig=AHkA5jQ1KIijEq81L6zemz59db_g&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AHkA5jQSH2z-ynDQhPp_cW7HGs_g&html=&pos=7&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Synthesizing inline security monitors for ICS using Generative AI and FormalBench", "first_label": [], "second_label": [], "data": "GE Raptis, MT Khan, C Koulamas, D Serpanos- 202551st Annual Conference of the, 2025\nIndustrial Control Systems (ICS) increasingly face cybersecurity threats due to their \ndistributed architecture and critical role in infrastructure operations. We adopt inline \nsecurity monitoring as a practical run-time verification strategy to address these risks. \nHowever, authoring formal specifications remains time-consuming and error-prone, \nrequiring deep domain expertise. In this paper, we explore how large language \nmodels (LLMs) can support the synthesis of inline security monitors by generating\nTrch dn: Can LLMs Reason About Program Semantics? A Comprehensive", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11221437/&hl=vi&sa=X&d=4986496400592953618&ei=SUB1aaviCoeUywS5-prpDw&scisig=AHkA5jSv0VI5Sd1XOOFeAkHXYqAO&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:AHkA5jTPS8thqNJxu8pHnPo4odW8&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["3 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "Catching common vulnerabilities with code language models", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "S Al Atiiq, C Gehrmann, K Khalil, K Dahln- 2025 IEEE Secure Development, 2025\nCode Language Model (code-LM)-based vulnerability detection for C/C++ faces a \nsubstantial challenge. Previous research has shown that even though it is better than \nany prior machine learning approach, it still struggles to generalize well, as shown by \nthe low F1 score. Prior works treated the problem as a binary classification: either \nvulnerable or non-vulnerable. Looking deeper at the various vulnerability types, we \nsee that this oversimplifies the problem, as different vulnerabilities have different\nTrch dn: Comparison of static application security testing tools and large", "link": "https://scholar.google.com/scholar_url?url=https://lup.lub.lu.se/record/4a13fc00-b39b-4ac7-8940-4fa571d55e8d&hl=vi&sa=X&d=189082203538347483&ei=SUB1aaviCoeUywS5-prpDw&scisig=AHkA5jTjPUaX2L9iudiwes9cnfeR&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:AHkA5jTPS8thqNJxu8pHnPo4odW8&html=&pos=1&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["3 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
