{"title": "Leveraging Intra-and Inter-References in vulnerability detection using Multi-Agent collaboration based on LLMs", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection", "Agent"], "data": "CN Tsai, J Xie, CM Lai, CS Lin- Cluster Computing, 2025\nAs AI technology advances, early detection of code vulnerabilities becomes \nincreasingly critical for preventing exploitation, reducing remediation costs, \nenhancing user trust, and improving system performance. Recently, Large language", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10586-025-05721-2&hl=vi&sa=X&d=10835680397604577360&ei=_LwLaf-lMaqy6rQP2YOFyAg&scisig=ABGrvjLvup8kWfy-ji1NVhu3K4zl&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "An Experimental Study of Real-Life LLM-Proposed Performance Improvements", "first_label": ["LLM"], "second_label": [], "data": "L Yi, G Gay, P Leitner- arXiv preprint arXiv:2510.15494, 2025\nLarge Language Models (LLMs) can generate code, but can they generate fast \ncode? In this paper, we study this question using a dataset of 65 real-world tasks \nmined from open-source Java programs. We specifically select tasks where", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.15494&hl=vi&sa=X&d=10640118915085146028&ei=_LwLaf-lMaqy6rQP2YOFyAg&scisig=ABGrvjLcRUj8NSio7-ggPhAhEwVg&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "LLM-Assisted Synthesis of High-Assurance C Programs", "first_label": ["LLM"], "second_label": [], "data": "P Mukherjee, M Lu, B Delaware - 2025\nWe present SYNVERa novel, general purpose synthesizer for C programs \nequipped with machine-checked proofs of correctness using the Verified Software \nToolchain. To do so, SYNVER employs two Large Language Models (LLMs): the first\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://prasitagit.github.io/papers/SynverPreprint.pdf&hl=vi&sa=X&d=10034668577701533579&ei=_LwLaf-lMaqy6rQP2YOFyAg&scisig=ABGrvjKedmUATdp-iuZhyQwb-bpX&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Self-Reflective Tool Learners: Learning When and Why to Use External Tools", "first_label": [], "second_label": [], "data": "D Williams, J Smith, S Rodriguez, A Deshmukh\nLarge language models (LLMs) have made significant advancements in performing \ncomplex tasks, yet the effective utilization of external tools remains a challenge. The \nconcept of Self-Reflective Tool Learners aims to address this issue by incorporating \na framework that emphasizes self-reflection in tool usage. This method enables \nmodels to assess task requirements continuously, allowing them to determine when \nand why to invoke external tools, thus improving both performance and efficiency\nTrch dn: PatchZero: Zero-shot automatic patch correctness assessment\u00a0\u00a0\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng li trch dn mi trong cc bi vit ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Haoran-Zhang-111/publication/397059122_Self-Reflective_Tool_Learners_Learning_When_and_Why_to_Use_External_Tools/links/69035f69368b49329fa8511c/Self-Reflective-Tool-Learners-Learning-When-and-Why-to-Use-External-Tools.pdf&hl=vi&sa=X&d=14918106266213185135&ei=_bwLaZ3NAe2ZieoP-Nvg6AY&scisig=ABGrvjJoQbbDyAeggx7NHkZ1zvbN&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:ABGrvjL2eoLgrMchC3yPzCtO9Gb4&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["1 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "Wisdom and Delusion of LLM Ensembles for Code Generation and Repair", "first_label": ["LLM", "Code"], "second_label": ["Repair", "Generation"], "data": "F Vallecillos-Ruiz, M Hort, L Moonen- arXiv preprint arXiv:2510.21513, 2025\nToday's pursuit of a single Large Language Model (LMM) for all software \nengineering tasks is resource-intensive and overlooks the potential benefits of \ncomplementarity, where different models contribute unique strengths. However, the", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.21513&hl=vi&sa=X&d=7414273881583577151&ei=KDkKaaqCGOSv6rQPh5K9yQ8&scisig=ABGrvjJze_Gfx9_06SAKA-BlHAZz&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Vul-R2: A Reasoning LLM for Automated Vulnerability Repair", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Repair", "Reasoning"], "data": "XC Wen, Z Lin, Y Yang, C Gao, D Ye- arXiv preprint arXiv:2510.05480, 2025\nThe exponential increase in software vulnerabilities has created an urgent need for \nautomatic vulnerability repair (AVR) solutions. Recent research has formulated AVR \nas a sequence generation problem and has leveraged large language models", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.05480&hl=vi&sa=X&d=17087307418542281791&ei=KDkKaaqCGOSv6rQPh5K9yQ8&scisig=ABGrvjJlsQcjOBCSZutD9pRzL3u0&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "SemOpt: LLM-Driven Code Optimization via Rule-Based Analysis", "first_label": ["LLM", "Code"], "second_label": [], "data": "Y Zhao, YA Xiao, Q Xiao, Z Zhang, Y Xiong- arXiv preprint arXiv:2510.16384, 2025\nAutomated code optimization aims to improve performance in programs by \nrefactoring code, and recent studies focus on utilizing LLMs for the optimization. \nTypical existing approaches mine optimization commits from open-source", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.16384&hl=vi&sa=X&d=17733183336457524325&ei=KDkKaaqCGOSv6rQPh5K9yQ8&scisig=ABGrvjIdTJLV1wH4Tm1656yfT86T&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "SecureReviewer: Enhancing Large Language Models for Secure Code Review through Secure-aware Fine-tuning", "first_label": ["LLM", "Code Review", "Code"], "second_label": [], "data": "F Liu, S Liu, Y Zhu, X Lian, L Zhang- arXiv preprint arXiv:2510.26457, 2025\nIdentifying and addressing security issues during the early phase of the development \nlifecycle is critical for mitigating the long-term negative impacts on software systems. \nCode review serves as an effective practice that enables developers to check their", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.26457&hl=vi&sa=X&d=2750772061662092214&ei=KDkKaaqCGOSv6rQPh5K9yQ8&scisig=ABGrvjJCIQLgS8ShLO-ChXzeoUuk&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Source Code Guardrail: AI Driven Solution to Distinguish Critical vs. Generic Code for Enterprise LLM Security", "first_label": ["LLM", "Code"], "second_label": [], "data": "R Sharma, A Gupta- International Conference on Provable Security, 2025\nAbstract The adoption of Large Language Models (LLMs) in businesses raises the \npossibility of inadvertent intellectual property (IP) and secret data leaks to public \nartificial intelligence systems. Organizations are using security solutions, including", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-95-2961-2_23&hl=vi&sa=X&d=5184326828152072441&ei=KDkKaaqCGOSv6rQPh5K9yQ8&scisig=ABGrvjJOJG-OQ4wH-x-OhS5wRNe2&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "MirrorFuzz: Leveraging LLM and Shared Bugs for Deep Learning Framework APIs Fuzzing", "first_label": ["LLM", "Fuzzing", "Bug"], "second_label": [], "data": "S Ou, Y Li, L Yu, C Wei, T Wen, Q Chen, Y Chen- IEEE Transactions on, 2025\nDeep learning (DL) frameworks serve as the backbone for a wide range of artificial \nintelligence applications. However, bugs within DL frameworks can cascade into \ncritical issues in higher-level applications, jeopardizing reliability and security. While", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/32/4359463/11201027.pdf&hl=vi&sa=X&d=1422528139240657868&ei=KDkKaaqCGOSv6rQPh5K9yQ8&scisig=ABGrvjI1tTlw2XwsJvzcyylBVxMq&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "TIT: A Tree-Structured Instruction Tuning Approach for LLM-Based Code Translation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "H Jiang, Y Wang, H Lin, P Zou, Z Zhou, A Jia, X Li- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) have shown strong performance in automated \nsource-to-target code translation through pretraining on extensive code corpora. \nHowever, mainstream LLM-based code translation methods suffer from two critical", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.09400&hl=vi&sa=X&d=13736189209612319180&ei=KDkKaaqCGOSv6rQPh5K9yQ8&scisig=ABGrvjLfQpVO1yEU3BC2VHg0FKp1&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Enhancing LLM's Ability to Generate More Repository-Aware Unit Tests Through Precise Context Injection", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "X Yin, C Ni, X Li, L Chen, G Ma, X Yang\nRecently, Large Language Models (LLMs) have gained attention for their ability to \nhandle a broad range of tasks, including unit test generation. Despite their success, \nLLMs may exhibit hallucinations when generating unit tests for focal methods or", "link": "https://scholar.google.com/scholar_url?url=https://vinci-grape.github.io/papers/Enhancing_LLM_s_Ability_to_Generate_More_Repository_Aware_Unit_Tests_Through_Precise_Context_Injection.pdf&hl=vi&sa=X&d=3506872574868649515&ei=KDkKaaqCGOSv6rQPh5K9yQ8&scisig=ABGrvjKPA0zq2FXS1WyPoCr65qwT&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=7&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Adaptive Proof Refinement with LLM-Guided Strategy Selection", "first_label": ["LLM"], "second_label": [], "data": "M Lu, Z Zhou, D Xie, S Jia, B Delaware, T Zhang- arXiv preprint arXiv:2510.25103, 2025\nFormal verification via theorem proving enables the expressive specification and \nrigorous proof of software correctness, but it is difficult to scale due to the significant \nmanual effort and expertise required. While Large Language Models (LLMs) show", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.25103&hl=vi&sa=X&d=5975204416659974907&ei=KDkKaaqCGOSv6rQPh5K9yQ8&scisig=ABGrvjKkxpZfzPdYuZ4UtGP1F_PP&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=8&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Understanding LLM-Driven Test Oracle Generation", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "A Bodicoat, G Jahangirova, V Terragni\nAutomated unit test generation aims to improve software quality while reducing the \ntime and effort required for creating tests manually. However, existing techniques \nprimarily generate regression oracles that predicate on the implemented behavior of\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Valerio-Terragni/publication/397039765_Understanding_LLM-Driven_Test_Oracle_Generation/links/6902c057c900be105cbdb064/Understanding-LLM-Driven-Test-Oracle-Generation.pdf&hl=vi&sa=X&d=12097821390559666401&ei=KDkKaaqCGOSv6rQPh5K9yQ8&scisig=ABGrvjIXkDwyMD9hFiuIe4cSDy3c&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=9&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Is Your Prompt Poisoning Code? Defect Induction Rates and Security Mitigation Strategies", "first_label": ["Code", "Software Defect"], "second_label": [], "data": "B Wang, YL Zhong, MD Wan, WJ Yu, YB Ouyang- arXiv preprint arXiv, 2025\nLarge language models (LLMs) have become indispensable for automated code \ngeneration, yet the quality and security of their outputs remain a critical concern. \nExisting studies predominantly concentrate on adversarial attacks or inherent flaws \nwithin the models. However, a more prevalent yet underexplored issue concerns \nhow the quality of a benign but poorly formulated prompt affects the security of the \ngenerated code. To investigate this, we first propose an evaluation framework for\nTrch dn: Refining chatgpt-generated code: Characterizing and mitigating\u00a0\u00a0\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng li trch dn mi trong cc bi vit ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.22944&hl=vi&sa=X&d=14215146240991081594&ei=KDkKaealJMHO6rQPjanaqAg&scisig=ABGrvjJhefshV2c262vq2lsz1aMv&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:ABGrvjL2eoLgrMchC3yPzCtO9Gb4&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["1 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
