{"title": "Red Teaming Program Repair Agents: When Correct Patches can Hide Vulnerabilities", "first_label": ["Vulnerabilities", "APR"], "second_label": ["Repair", "Agent"], "data": "S Chen, Y He, S Jana, B Ray- arXiv preprint arXiv:2509.25894, 2025\nLLM-based agents are increasingly deployed for software maintenance tasks such \nas automated program repair (APR). APR agents automatically fetch GitHub issues \nand use backend LLMs to generate patches that fix the reported bugs. However", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25894&hl=vi&sa=X&d=17829160501867046335&ei=5QnhaIOsHMyR6rQP8M_xgAM&scisig=AAZF9b9xoBNSp2DVGtyfC25OhwWn&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Explainable Fault Localization for Programming Assignments via LLM-Guided Annotation", "first_label": ["LLM", "Fault Localization"], "second_label": ["Localization"], "data": "F Liu, T Wang, L Zhang, Z Yang, J Jiang, Z Sun- arXiv preprint arXiv:2509.25676, 2025\nProviding timely and personalized guidance for students' programming assignments, \noffers significant practical value for helping students complete assignments and \nenhance their learning. In recent years, various automated Fault Localization (FL)", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25676&hl=vi&sa=X&d=16831300563596066577&ei=5QnhaIOsHMyR6rQP8M_xgAM&scisig=AAZF9b8KiRs4870r1KbKTYTF0UyR&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "A Scalable Vulnerability Detection System with Multi-View Graph Representations", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Graph"], "data": "S Dou, H Zheng, J Shan, Y Wu, D Zou, X Huang, Y Liu- ACM Transactions on, 2025\nDeep learning (DL) has been extensively utilized in source code vulnerability \ndetection due to its robust automatic feature extraction capabilities. To achieve \nscalable vulnerability scanning, some prior studies intend to process the source code", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3770075&hl=vi&sa=X&d=14953216934661661615&ei=5QnhaIOsHMyR6rQP8M_xgAM&scisig=AAZF9b-mdJedTULsxLZv6yXH09xW&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Cross-Domain Evaluation of Transformer-Based Vulnerability Detection on Open & Industry Data", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "M Mock, T Forrer, B Russo- arXiv preprint arXiv:2509.09313, 2025\nDeep learning solutions for vulnerability detection proposed in academic research \nare not always accessible to developers, and their applicability in industrial settings \nis rarely addressed. Transferring such technologies from academia to industry", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.09313&hl=vi&sa=X&d=3896104068122220271&ei=5QnhaIOsHMyR6rQP8M_xgAM&scisig=AAZF9b-3QAzHZH6Dtl2JLErNC_cZ&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "SLD-Spec: Enhancement LLM-assisted Specification Generation for Complex Loop Functions via Program Slicing and Logical Deletion", "first_label": ["LLM"], "second_label": ["Generation"], "data": "Z Chen, L Zhang, Z Zhang, JJ Zhang, R Zhou, Y Shen- arXiv preprint arXiv, 2025\nAutomatically generating formal specifications from program code can greatly \nenhance the efficiency of program verification and enable end-to-end automation \nfrom requirements to reliable software. However, existing LLM-based approaches", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.09917&hl=vi&sa=X&d=2122673112308488324&ei=5QnhaIOsHMyR6rQP8M_xgAM&scisig=AAZF9b-CuDfsPWCmN1n_oNohxVgn&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Local Agentic RAG-Based Information System Development for Intelligent Analysis of GitHub Code Repositories in Computer Science Education", "first_label": ["Code"], "second_label": ["Agent"], "data": "Z Hu, MM Paprotskyi, V Vysotska, L Chyrun, Y Ushenko\nThis study presents the development and evaluation of a local agent-based Retrieval-\nAugmented Generation (Agentic RAG) system designed for the intelligent analysis of \nGitHub repositories in computer science education and IT practice. The novelty of\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://www.mecs-press.org/ijmecs/ijmecs-v17-n5/IJMECS-V17-N5-7.pdf&hl=vi&sa=X&d=15899062735032558573&ei=5QnhaIOsHMyR6rQP8M_xgAM&scisig=AAZF9b9zpITZz-kJHGT1UMgEWtn4&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "BloomAPR: A Bloom's Taxonomy-based Framework for Assessing the Capabilities of LLM-Powered APR Solutions", "first_label": ["LLM"], "second_label": [], "data": "Y Ma, J Shin, L Da Silva, Z Ming, S Wang, F Khomh- arXiv preprint arXiv, 2025\nRecent advances in large language models (LLMs) have accelerated the \ndevelopment of AI-driven automated program repair (APR) solutions. However, these \nsolutions are typically evaluated using static benchmarks such as Defects4J and \nSWE-bench, which suffer from two key limitations:(1) the risk of data contamination, \npotentially inflating evaluation results due to overlap with LLM training data, and (2) \nlimited ability to assess the APR capabilities in dynamic and diverse contexts. In this\nTrch dn: Invalidator: Automated patch correctness assessment via semantic", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25465&hl=vi&sa=X&d=11066311399156471814&ei=5QnhaPeuJtvTieoP4fTokAI&scisig=AAZF9b8-WlUSvsvzUFkBWMfotWY9&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:AAZF9b-KfaIzNELg_AxYHyYLV6lH&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["4 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "A Benchmark for Localizing Code and Non-Code Issues in Software Projects", "first_label": ["Code"], "second_label": [], "data": "Z Zhang, J Wang, Q Yang, Y Pan, Y Tang, Y Li, Z Xing- arXiv preprint arXiv, 2025\nAccurate project localization (eg, files and functions) for issue resolution is a critical \nfirst step in software maintenance. However, existing benchmarks for issue \nlocalization, such as SWE-Bench and LocBench, are limited. They focus \npredominantly on pull-request issues and code locations, ignoring other evidence \nand non-code files such as commits, comments, configurations, and documentation. \nTo address this gap, we introduce MULocBench, a comprehensive dataset of 1,100\nTrch dn: Thanh Le-Cong, Ratnadira Widyasari, Chakkrit Tantithamthavorn", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25242&hl=vi&sa=X&d=9912554073922702978&ei=5QnhaPeuJtvTieoP4fTokAI&scisig=AAZF9b8mdC7vfC9M85hnC5hsZ66A&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:AAZF9b-KfaIzNELg_AxYHyYLV6lH&html=&pos=1&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["4 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "Comparison of Language Models for Source Code Vulnerability Classification", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": [], "data": "KI Gladkikh, AA Zakharov- 2025 International Russian Automation Conference, 2025\nModern large language models (LLMs) have demonstrated strong performance in \nthe static analysis of source code for security vulnerabilities. With new LLMs \nemerging daily, they differ in architecture, prompting strategies, and their overall \ncapacity to understand source code. In this study, we developed a benchmarking \nframework to evaluate a range of LLMs on vulnerability detection tasks using multiple \nperformance metrics. The results indicate that models from the Qwen family achieve\nTrch dn: Comparison of static application security testing tools and large", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11177346/&hl=vi&sa=X&d=5404891364929924575&ei=5QnhaPeuJtvTieoP4fTokAI&scisig=AAZF9b8a5z_BUYvzSELnbAZ27iIJ&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:AAZF9b-KfaIzNELg_AxYHyYLV6lH&html=&pos=2&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["4 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "From Vibe to Vise Coding: Addressing the AI-Generated Code Quality Crisis", "first_label": ["Code"], "second_label": [], "data": "D Farag- Softwaretechnik-Trends Band 45, Heft 3, 2025\nCurrent news claims that AI is replacing software developers [20, 31, 32]. However, \nsuch proclamations may primarily serve corporate narratives (like justifying layoffs or \npromoting AI products) rather than reflect reality. We examine data on AI adoption \nand its effects, revealing that AI-assisted software development (AI coding for short) \nimproves, but software engineering is far from full automation: The current hype often \nfails to distinguish between what large language models (LLMs) can and cannot do\nTrch dn: Refining chatgpt-generated code: Characterizing and mitigating\u00a0\u00a0\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng li trch dn mi trong cc bi vit ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://dl.gi.de/server/api/core/bitstreams/f8fe787e-2367-4e40-a79c-ee2f183193de/content&hl=vi&sa=X&d=17953142790972084078&ei=5QnhaPeuJtvTieoP4fTokAI&scisig=AAZF9b9zBjfXX4ndNh-g005IpefL&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:AAZF9b-KfaIzNELg_AxYHyYLV6lH&html=&pos=3&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["4 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "What Do They Fix? LLM-Aided Categorization of Security Patches for Critical Memory Bugs", "first_label": ["LLM", "Bug"], "second_label": [], "data": "X Li, J Pu, Y Wu, X Zou, S Zhu, Q Wu, Z Zhang, J Hsu- arXiv preprint arXiv, 2025\nOpen-source software projects are foundational to modern software ecosystems, with \nthe Linux kernel standing out as a critical exemplar due to its ubiquity and \ncomplexity. Although security patches are continuously integrated into the Linux", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.22796&hl=vi&sa=X&d=5877456260761011502&ei=7m_faLjrDq3M6rQPuqaCiA0&scisig=AAZF9b_K5bVx20Ft-L-epPjLrGqv&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Adversarial Bug Reports as a Security Risk in Language Model-Based Automated Program Repair", "first_label": ["APR", "LLM", "Bug"], "second_label": ["Repair"], "data": "P Przymus, A Happe, J Cito- arXiv preprint arXiv:2509.05372, 2025\nLarge Language Model (LLM)-based Automated Program Repair (APR) systems are \nincreasingly integrated into modern software development workflows, offering \nautomated patches in response to natural language bug reports. However, this", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.05372&hl=vi&sa=X&d=17856431439942945890&ei=7m_faLjrDq3M6rQPuqaCiA0&scisig=AAZF9b9iNtxXJTJlEQXG_3JYQbs1&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Rethinking Kernel Program Repair: Benchmarking and Enhancing LLMs with RGym", "first_label": ["APR", "LLM"], "second_label": ["Repair"], "data": "K Shehada, Y Wu, WD Feng, A Iyer, G Kumfert, Y Ding- NeurIPS 2025 Workshop on\nLarge Language Models (LLMs) have revolutionized automated program repair \n(APR) but current benchmarks like SWE-Bench predominantly focus on userspace \napplications and overlook the complexities of kernel-space debugging and repair", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DNY4wv5C39G&hl=vi&sa=X&d=13284020585308537468&ei=7m_faLjrDq3M6rQPuqaCiA0&scisig=AAZF9b8qiQW2WOt5dhxoK0fl5lFh&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "When Code Crosses Borders: A Security-Centric Evaluation of LLM-based Code Translation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "H Chang, G Meng, S Xiao, K Chen, K Sun, Y Li- arXiv preprint arXiv:2509.06504, 2025\nWith the growing demand for cross-language codebase migration, evaluating LLMs' \nsecurity implications in translation tasks has become critical. Existing evaluations \nprimarily focus on syntactic or functional correctness at the function level, neglecting", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.06504&hl=vi&sa=X&d=15964686870607645440&ei=7m_faLjrDq3M6rQPuqaCiA0&scisig=AAZF9b9rJmR42d8IPErh15fFE3f8&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "DeepCodeProbe: Evaluating Code Representation Quality in Models Trained on Code", "first_label": ["Code"], "second_label": [], "data": "V Majdinasab, A Nikanjam, F Khomh- Empirical Software Engineering, 2025\nAbstract Machine Learning models trained on code and artifacts extracted from them \n(eg, version control histories, code differences, etc.), provide invaluable assistance \nfor software engineering tasks. Despite their good performance, there exists a lack of", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10664-025-10731-0&hl=vi&sa=X&d=4894546859526238222&ei=7m_faLjrDq3M6rQPuqaCiA0&scisig=AAZF9b9PrlAWMKjBTBOwWDVqSOtc&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Bridging Developer Instructions and Code Completion Through Instruction-Aware Fill-in-the-Middle Paradigm", "first_label": ["Code"], "second_label": ["Generation"], "data": "Z Sun, C Yang, C Peng, P Gao, X Du, L Li, D Lo- arXiv preprint arXiv:2509.24637, 2025\nLarge Language Models (LLMs) have significantly advanced code completion, yet \nthey often fail when the developer's intent is underspecified in the code context. To \naddress this, developers usually add natural language instructions (eg, comments)", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.24637&hl=vi&sa=X&d=17305794744039020422&ei=7m_faLjrDq3M6rQPuqaCiA0&scisig=AAZF9b-qDU6QAC4PPz9qG-_owbNR&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "From Cryptic to Clear-Training on LLM Explanations to Detect Smart Contract Vulnerabilities", "first_label": ["Vulnerabilities", "Smart Contracts", "LLM"], "second_label": [], "data": "Y Chen, Z Sun, G Wang, Q Liang, X Yu, D Hao- ACM Transactions on Software, 2025\nSmart contracts have revolutionized the way transactions are executed, offering \ndecentralized and immutable frameworks. The immutability of smart contracts poses \nsignificant risks when vulnerabilities exist in their code, leading to financial losses", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3765753&hl=vi&sa=X&d=10696251976758637118&ei=7m_faLjrDq3M6rQPuqaCiA0&scisig=AAZF9b9ZBf4NQYTpgMU9yATSPdqf&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Improving the Efficiency of LLM Agent Systems through Trajectory Reduction", "first_label": ["LLM"], "second_label": ["Agent"], "data": "YA Xiao, P Gao, C Peng, Y Xiong- arXiv preprint arXiv:2509.23586, 2025\nMulti-turn agent systems based on Large Language Models (LLMs) have been \nincreasingly popular for software engineering tasks. While LLM agents show decent \neffectiveness, the high computational cost of input tokens due to the ever-growing", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23586&hl=vi&sa=X&d=12596444921036280365&ei=7m_faLjrDq3M6rQPuqaCiA0&scisig=AAZF9b-Nsxb9BzRYoIftNViBPFg1&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=7&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Towards Human-interpretable Explanation in Code Clone Detection using LLM-based Post Hoc Explainer", "first_label": ["LLM", "Code"], "second_label": ["Detection"], "data": "T Racharak, C Ragkhitwetsagul, C Junplong- arXiv preprint arXiv, 2025\nRecent studies highlight various machine learning (ML)-based techniques for code \nclone detection, which can be integrated into developer tools such as static code \nanalysis. With the advancements brought by ML in code understanding, ML-based", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.22978&hl=vi&sa=X&d=13116222657243354012&ei=7m_faLjrDq3M6rQPuqaCiA0&scisig=AAZF9b-CrNTuw-vA-xt9R-PWj2rN&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=8&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "GTVD: a multi-level aggregation vulnerability detection method based on full-dependency program graph", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Graph"], "data": "H He, S Li, Y Li, Y Li- Cluster Computing, 2025\nIn modern software development life cycles, proactive vulnerability discovery and \nremediation play crucial roles in ensuring application security. However, current \ndeep learning-based vulnerability detection methods frequently face limitations due\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10586-025-05506-7&hl=vi&sa=X&d=9365356712912853263&ei=7m_faLjrDq3M6rQPuqaCiA0&scisig=AAZF9b_DdZ4fyL1mLj90wo4wpBRq&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=9&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "TF-Bench: Evaluating Program Semantics Reasoning with Type Inference in System F", "first_label": [], "second_label": ["Reasoning"], "data": "Y He, L Yang, CCG Gonzalo, H Chen- arXiv preprint arXiv:2509.23686, 2025\nLarge Language Models (LLMs) are increasingly integrated into the software \nengineering ecosystem. Their test-time compute (TTC) reasoning capabilities show \nsignificant potential for understanding program logic and semantics beyond mere \ntoken recognition. However, current benchmarks for code reasoning lack a formal, \nprogram-centric deductive framework to ensure sound evaluation, and are incapable \nof assessing whether models genuinely reason about program semantics or merely\nTrch dn: Can LLMs Reason About Program Semantics? A Comprehensive", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23686&hl=vi&sa=X&d=7812027363893781818&ei=7m_faKzQH56sieoP2PTggQg&scisig=AAZF9b921YNdLGMQG7M6UBXqYA2i&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:AAZF9b-KfaIzNELg_AxYHyYLV6lH&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["4 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "HFuzzer: Testing Large Language Models for Package Hallucinations via Phrase-based Fuzzing", "first_label": ["LLM", "Fuzzing", "Software Testing"], "second_label": [], "data": "Y Zhao, M Wu, X Hu, X Xia- arXiv preprint arXiv:2509.23835, 2025\nLarge Language Models (LLMs) are widely used for code generation, but they face \ncritical security risks when applied to practical production due to package \nhallucinations, in which LLMs recommend non-existent packages. These \nhallucinations can be exploited in software supply chain attacks, where malicious \nattackers exploit them to register harmful packages. It is critical to test LLMs for \npackage hallucinations to mitigate package hallucinations and defend against\nTrch dn: Refining chatgpt-generated code: Characterizing and mitigating", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23835&hl=vi&sa=X&d=16917587561815760773&ei=7m_faKzQH56sieoP2PTggQg&scisig=AAZF9b8Mk-rnOTcKAAGqO9tIlO4J&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:AAZF9b-KfaIzNELg_AxYHyYLV6lH&html=&pos=1&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["4 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "Automated Vulnerability Validation and Verification: A Large Language Model Approach", "first_label": ["Vulnerabilities", "Verification", "LLM"], "second_label": [], "data": "A Lotfi, C Katsis, E Bertino- arXiv preprint arXiv:2509.24037, 2025\nSoftware vulnerabilities remain a critical security challenge, providing entry points for \nattackers into enterprise networks. Despite advances in security practices, the lack of \nhigh-quality datasets capturing diverse exploit behavior limits effective vulnerability \nassessment and mitigation. This paper introduces an end-to-end multi-step pipeline \nleveraging generative AI, specifically large language models (LLMs), to address the \nchallenges of orchestrating and reproducing attacks to known software\nTrch dn: Refining chatgpt-generated code: Characterizing and mitigating", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.24037&hl=vi&sa=X&d=7978409907240033186&ei=7m_faKzQH56sieoP2PTggQg&scisig=AAZF9b8QoVaounWNCXofucwywvLP&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:AAZF9b-KfaIzNELg_AxYHyYLV6lH&html=&pos=2&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["4 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "Metamorphic Testing of Deep Code Models: A Systematic", "first_label": ["Code", "Software Testing"], "second_label": [], "data": "ALI ASGARI, M DE KONING, P DERAKHSHANFAR - 2025\nIn recent years, large language models for code (LLM4Code) have achieved \nremarkable performance across a range of software engineering tasks, reaching \naccuracy levels that make them increasingly viable for real-world adoption. These \ntasks include, but are not limited to, program repair [1], vulnerability detection [2, 3], \ncode completion [4, 5], and clone detection [6, 7], among others. However, the \npractical applicability of LLM4Code depends not only on their performance on\nTrch dn: Evaluating program repair with semantic-preserving\u00a0\u00a0\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng li trch dn mi trong cc bi vit ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Annibale-Panichella/publication/395486459_Metamorphic_Testing_of_Deep_Code_Models_A_Systematic_Literature_Review/links/68d12186220a341aa14e4b74/Metamorphic-Testing-of-Deep-Code-Models-A-Systematic-Literature-Review.pdf&hl=vi&sa=X&d=4283050785129156787&ei=7m_faKzQH56sieoP2PTggQg&scisig=AAZF9b8CPVZTSsxHUaaieQPV0b6M&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:AAZF9b-KfaIzNELg_AxYHyYLV6lH&html=&pos=3&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["4 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
