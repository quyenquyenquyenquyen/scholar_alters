{"title": "Analyzing the Instability of Large Language Models in Automated Bug Injection and Correction", "first_label": ["LLM", "Bug"], "second_label": [], "data": "MB Er, N lhan, U Kuran- arXiv preprint arXiv:2509.06429, 2025\nThe use of Large Language Models (LLMs) in software engineering tasks is growing, \nespecially in the areas of bug fixing and code generation. Nevertheless, these \nmodels often yield unstable results; when executed at different times with the same \ninput, they can generate radically different code. The consistency of LLMs in bug-\nfixing tasks has not yet been thoroughly assessed, despite the fact that this instability \nhas typically been discussed in the literature in relation to code generation. The\nTrch dn: Refining chatgpt-generated code: Characterizing and mitigating", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.06429&hl=vi&sa=X&d=9353035016619851347&ei=WEzFaIXEH52j6rQPy-rI8A0&scisig=AAZF9b8JgkbKTMgP2t7mpPOd5aMA&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:AAZF9b-KfaIzNELg_AxYHyYLV6lH&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["2 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "Empirical Evaluation of AI-Based Security Scanning andSonarQube in DevSecOps Pipelines", "first_label": [], "second_label": [], "data": "A Abueshareik, A Katbeh - 2025\nContext: Security scanning is a critical part of software development in modern \nDevSecOps pipelines, and detecting security vulnerabilities early in development is \ncritical to maintaining a secure codebase. Objective: This study conducts a \nbenchmarking evaluation to compare large language model (LLM)-based security \nscanning against static application security testing (SAST) using SonarQube to \ndetect security vulnerabilities in historical commits in open-source repositories\nTrch dn: Comparison of static application security testing tools and large\u00a0\u00a0\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng li trch dn mi trong cc bi vit ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://www.diva-portal.org/smash/get/diva2:1995456/FULLTEXT01.pdf&hl=vi&sa=X&d=7210586187229613794&ei=WEzFaIXEH52j6rQPy-rI8A0&scisig=AAZF9b85Eb69a1dbZtJwY7130001&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:AAZF9b-KfaIzNELg_AxYHyYLV6lH&html=&pos=1&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["2 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "Conversational Automated Program Repair for ARM Assembly Code using LLMs", "first_label": ["APR", "LLM", "Code"], "second_label": ["Repair"], "data": "J Gomes, D Silveira, T Jorge\nThis paper explores the development of the Automated Program Repair (APR) field, \nwith a specific emphasis on the use of Large Language Models (LLMs) to tackle the \nchallenges of ARM assembly code in the AIR project, a joint initiative between GMV", "link": "https://scholar.google.com/scholar_url?url=https://www.horizon-schumann.eu/wp-content/uploads/2025/07/Conversational_Automated_Program_Repair_for_ARM_Assembly_Code_using_LLMs_final.pdf&hl=vi&sa=X&d=4367788842176228212&ei=WEzFaMamE5u1ieoP1tDwoQs&scisig=AAZF9b_8xrU3osMG0qpQXxLpnrK7&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Adversarial Bug Reports as a Security Risk in Language Model-Based Automated Program Repair", "first_label": ["APR", "LLM", "Bug"], "second_label": ["Repair"], "data": "P Przymus, A Happe, J Cito- arXiv preprint arXiv:2509.05372, 2025\nLarge Language Model (LLM)-based Automated Program Repair (APR) systems are \nincreasingly integrated into modern software development workflows, offering \nautomated patches in response to natural language bug reports. However, this", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.05372&hl=vi&sa=X&d=17856431439942945890&ei=WEzFaMamE5u1ieoP1tDwoQs&scisig=AAZF9b9iNtxXJTJlEQXG_3JYQbs1&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Empirical Study of Code Large Language Models for Binary Security Patch Detection", "first_label": ["LLM", "Code"], "second_label": ["Detection"], "data": "Q Li, B Li, C Gao, S Gao, Z Li- arXiv preprint arXiv:2509.06052, 2025\nSecurity patch detection (SPD) is crucial for maintaining software security, as \nunpatched vulnerabilities can lead to severe security risks. In recent years, numerous \nlearning-based SPD approaches have demonstrated promising results on source", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.06052&hl=vi&sa=X&d=13188995808337954619&ei=WEzFaMamE5u1ieoP1tDwoQs&scisig=AAZF9b-uojbuOzp9rZgBIMmU6x4h&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "CigaR: Minimizing LLM Costs for Program Repair", "first_label": ["APR", "LLM"], "second_label": ["Repair"], "data": "K Etemadi\nRecently, Large Language Models (LLMs) are widely used to automatically fix bugs \n[1]. However, we still have to study how much such repair methods cost. The tokens \nsent to the LLM (request) and the tokens they generate (response) are the main", "link": "https://scholar.google.com/scholar_url?url=https://internal.wasp-sweden.org/winterconf2024/posters/khashayar_etemadi.pdf&hl=vi&sa=X&d=7097105288725132822&ei=WEzFaMamE5u1ieoP1tDwoQs&scisig=AAZF9b9nnE46U-0oT2-kC0t-0EtE&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "RINSER: Accurate API Prediction Using Masked Language Models", "first_label": ["LLM"], "second_label": [], "data": "ME Ahmed, C Cody, M Ikram, S Lamont, A Abuadbba- arXiv preprint arXiv, 2025\nMalware authors commonly use obfuscation to hide API identities in binary files, \nmaking analysis difficult and time-consuming for a human expert to understand the \nbehavior and intent of the program. Automatic API prediction tools are necessary to\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.04887&hl=vi&sa=X&d=506950802035833113&ei=WEzFaMamE5u1ieoP1tDwoQs&scisig=AAZF9b9est9GZVI49yC-Sw26XsEw&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
