{"title": "A data-augmented model routing framework for efficient LLM deployment in edgecloud environments: MSM Pozi, Y. Sato", "first_label": ["LLM"], "second_label": [], "data": "MSM Pozi, Y Sato- The Journal of Supercomputing, 2025\nLarge language model (LLM)-based program generation tasks are hindered by high \ncomputational demands. These challenges, along with high deployment costs, often \npose a barrier to practical applications. To address these, we propose a novel data", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s11227-025-08034-8&hl=vi&sa=X&d=3548574653858656275&ei=iuBDaaLMCd_OieoPg6WE2QY&scisig=ALhkC2Q4-VJc0taO10AjW_V1NOD2&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ALhkC2T2gGOcVPTEcMFcARghNUJN&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "KTester: Leveraging Domain and Testing Knowledge for More Effective LLM-based Test Generation", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "A Li, M Liu, Z Chen, Z Pei, Z Li, D Dai, Y Wang, Z Zheng- arXiv preprint arXiv, 2025\nAutomated unit test generation using large language models (LLMs) holds great \npromise but often struggles with generating tests that are both correct and \nmaintainable in real-world projects. This paper presents KTester, a novel framework", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.14224&hl=vi&sa=X&d=10983934054869938261&ei=iuBDaaLMCd_OieoPg6WE2QY&scisig=ALhkC2SnqeAXUhGFyjUYbpo2ILAS&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ALhkC2T2gGOcVPTEcMFcARghNUJN&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "CIV: Leveraging Causal Subgraphs of Vulnerability for Noise Reduction in Vulnerability Detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Graph"], "data": "Z Gao, L Xiao, X Du, Y Xing- Expert Systems with Applications, 2025\nAccurate vulnerability detection is critical for software security. Although deep \nlearning-based vulnerability detection methods have shown promise in this task, they \ninclude much information unrelated to vulnerability semantics, which we call noise", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0957417425040072&hl=vi&sa=X&d=1911796227503386901&ei=iuBDaaLMCd_OieoPg6WE2QY&scisig=ALhkC2RYTrdtkri1T9-q3e3-4G2W&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ALhkC2T2gGOcVPTEcMFcARghNUJN&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "The Cost of AI-Assisted Coding: Energy vs. Accuracy in Language Models", "first_label": ["LLM"], "second_label": [], "data": "N Alizadeh, B Belchev, N Saurabh, P Kelbert - 2025\nGenerative Large Language Models (LLMs) have become widely accessible since \nthe release of ChatGPT in late 2022 [2], and their adoption nearly doubled in under \nsix months [3]. In addition, the majority of developers find code-specific AI models", "link": "https://scholar.google.com/scholar_url?url=https://benevol2025.github.io/pre/paper03.pdf&hl=vi&sa=X&d=3874342652444288509&ei=iuBDaaLMCd_OieoPg6WE2QY&scisig=ALhkC2Rn562zMHnFoj6JiddHdWsr&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ALhkC2T2gGOcVPTEcMFcARghNUJN&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "CrossPyEval: Enhancing LLM-based Evaluation of Low-Resource Code via Code Translation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "W Wu, LI Wu, G Li- The 17th Asian Conference on Machine Learning, 2025\nLarge language models (LLMs) have demonstrated remarkable performance in code \ngeneration and evaluation tasks, particularly for Python, which dominates the pre-\ntraining corpora. However, the evaluation of code in low-resource programming\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3D5qiFpW4lWH&hl=vi&sa=X&d=15885618439171632205&ei=iuBDaaLMCd_OieoPg6WE2QY&scisig=ALhkC2SIGNUB0bs_75fnhmkDha8R&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ALhkC2T2gGOcVPTEcMFcARghNUJN&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Adapting Language Models for Low-Resource Programming Languages", "first_label": ["LLM"], "second_label": [], "data": "A Singha, M Singh, H Hasanbeig, A Radhakrishna- NeurIPS 2025 Fourth Workshop on\nLarge Language Models (LLMs) have achieved remarkable success in code \ngeneration, yet their capabilities remain predominantly concentrated in well-\nresourced programming languages such as Python and Java. In contrast, low\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3D2ctRK8h3AZ&hl=vi&sa=X&d=10639384588679978541&ei=60BCadhJubbqtA-CleJI&scisig=ALhkC2TU1E8-xJojBcX0Q0YHF0cb&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ALhkC2T2gGOcVPTEcMFcARghNUJN&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Improving Quality in AI-Generated Code through Prompt Engineering: An Evaluation of the Impact of Prompting Techniques on Software Quality in Code Generated by", "first_label": ["Code"], "second_label": [], "data": "M Paulsson - 2025\nAbstract The use of Large Language Models (LLMs) for code generation is rapidly \nincreasing. While previous investigations on the correctness of AI-generated code \nare widely present, less focus has been placed on the code's further quality attributes \nand how it can be improved. An aspect that can be equally important. This thesis \naims to fill this gap by investigating how LLMs can be guided to generate code that \naligns with software quality principles. Using a mixed methods approach, the study\nTrch dn: Thanh Le-Cong, Ratnadira Widyasari, Chakkrit Tantithamthavorn\u00a0\u00a0\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng li trch dn mi trong cc bi vit ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://www.diva-portal.org/smash/get/diva2:1999528/FULLTEXT01.pdf&hl=vi&sa=X&d=16193075811331607910&ei=60BCaYTwC72qieoPuKej0QM&scisig=ALhkC2TTDz5-urwF1NNor-xk3yYw&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:ALhkC2S5kr7kHUQq0DGLL-ZCgBVB&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["1 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
