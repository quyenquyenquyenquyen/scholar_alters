{"title": "LoCoBench-Agent: An Interactive Benchmark for LLM Agents in Long-Context Software Engineering", "first_label": ["LLM"], "second_label": ["Agent"], "data": "J Qiu, Z Liu, Z Liu, R Murthy, J Zhang, H Chen, S Wang- arXiv preprint arXiv, 2025\nAs large language models (LLMs) evolve into sophisticated autonomous agents \ncapable of complex software development tasks, evaluating their real-world \ncapabilities becomes critical. While existing benchmarks like LoCoBench~\\cite", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.13998&hl=vi&sa=X&d=5068327394060475494&ei=60g3afviMruZ6rQP9aakkAE&scisig=ALhkC2RovNoV0ywYVr4A68T8Kt-V&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ALhkC2T2gGOcVPTEcMFcARghNUJN&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "KTester: Leveraging Domain and Testing Knowledge for More Effective LLM-based Test Generation", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "A Li, M Liu, Z Chen, Z Pei, Z Li, D Dai, Y Wang, Z Zheng- arXiv preprint arXiv, 2025\nAutomated unit test generation using large language models (LLMs) holds great \npromise but often struggles with generating tests that are both correct and \nmaintainable in real-world projects. This paper presents KTester, a novel framework", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.14224&hl=vi&sa=X&d=10983934054869938261&ei=60g3afviMruZ6rQP9aakkAE&scisig=ALhkC2SnqeAXUhGFyjUYbpo2ILAS&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ALhkC2T2gGOcVPTEcMFcARghNUJN&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Go-UT-Bench: A Fine-Tuning Dataset for LLM-Based Unit Test Generation in Go", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "Y Pipalani, H Raj, R Ghosh, V Bhargava, D Dutta- arXiv preprint arXiv:2511.10868, 2025\nTraining data imbalance poses a major challenge for code LLMs. Most available \ndata heavily over represents raw opensource code while underrepresenting broader \nsoftware engineering tasks, especially in low resource languages like Golang. As a", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.10868&hl=vi&sa=X&d=16451546716691370203&ei=60g3afviMruZ6rQP9aakkAE&scisig=ALhkC2S7c4klrU0tkIMOQ5Ni8xrY&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ALhkC2T2gGOcVPTEcMFcARghNUJN&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "The Cost of AI-Assisted Coding: Energy vs. Accuracy in Language Models", "first_label": ["LLM"], "second_label": [], "data": "N Alizadeh, B Belchev, N Saurabh, P Kelbert - 2025\nGenerative Large Language Models (LLMs) have become widely accessible since \nthe release of ChatGPT in late 2022 [2], and their adoption nearly doubled in under \nsix months [3]. In addition, the majority of developers find code-specific AI models\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://benevol2025.github.io/pre/paper03.pdf&hl=vi&sa=X&d=3874342652444288509&ei=60g3afviMruZ6rQP9aakkAE&scisig=ALhkC2Rn562zMHnFoj6JiddHdWsr&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ALhkC2T2gGOcVPTEcMFcARghNUJN&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
