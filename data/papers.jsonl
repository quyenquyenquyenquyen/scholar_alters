{"title": "Emotional Strain and Frustration in LLM Interactions in Software Engineering", "first_label": ["LLM"], "second_label": [], "data": "C Martinez Montes, R Khojah- Proceedings of the 29th International Conference on, 2025\nLarge Language Models (LLMs) are increasingly integrated into various daily tasks \nin Software Engineering, such as coding and requirement elicitation. Despite their \nvarious capabilities and constant use, some interactions can lead to unexpected \nchallenges (eg hallucinations or verbose answers) and, in turn, cause emotions that \ndevelop into frustration. Frustration can negatively impact engineers' productivity and \nwell-being if it escalates into stress and burnout. In this paper, we assess the impact\nTrch dn: Refining chatgpt-generated code: Characterizing and mitigating", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3756681.3756951&hl=vi&sa=X&d=2966201137299157900&ei=A_tPaY6xH9KV6rQP84i9kQc&scisig=ALhkC2TqiGNRYUO9Ab-Za6ntvuyX&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:ALhkC2S5kr7kHUQq0DGLL-ZCgBVB&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["2 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "CodeQUEST: Evaluation and Improvement of Code Quality Using LLMs", "first_label": ["LLM", "Code"], "second_label": [], "data": "R Lius, A Frade, A Vaidya, M Labonne, M Kaiser- 2025 IEEE 36th, 2025\nThis paper presents CodeQUEST, an innovative framework leveraging Large \nLanguage Models (LLMs) to iteratively assess and enhance code quality across \nvarious dimensions, adhering to software engineering best practices. CodeQUEST \nconsists of two main components: the Evaluator, which provides quantitative scores \nand qualitative summaries to assess code quality, and the Optimizer, which refines \nthe code iteratively based on Evaluator feedback. Applying CodeQUEST to a curated\nTrch dn: Refining chatgpt-generated code: Characterizing and mitigating\u00a0\u00a0\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng li trch dn mi trong cc bi vit ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11262341/&hl=vi&sa=X&d=13371552476892238870&ei=A_tPaY6xH9KV6rQP84i9kQc&scisig=ALhkC2Q1yN5Yek-t8SFmgKpWoep1&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:ALhkC2S5kr7kHUQq0DGLL-ZCgBVB&html=&pos=1&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["2 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "Well Begun is Half Done: Location-Aware and Trace-Guided Iterative Automated Vulnerability Repair", "first_label": ["Vulnerabilities"], "second_label": ["Repair"], "data": "Z Ye, X Sun, S Cao, L Bo, B Li- arXiv preprint arXiv:2512.20203, 2025\nThe advances of large language models (LLMs) have paved the way for automated \nsoftware vulnerability repair approaches, which iteratively refine the patch until it \nbecomes plausible. Nevertheless, existing LLM-based vulnerability repair", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.20203&hl=vi&sa=X&d=8451094022554164496&ei=A_tPaZjXEqC16rQPm4fPgQQ&scisig=ALhkC2RPF725ybz89FzNOIoqd99X&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ALhkC2T2gGOcVPTEcMFcARghNUJN&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Toward Explaining Large Language Models in Software Engineering Tasks", "first_label": ["LLM"], "second_label": [], "data": "A Vitale, KN Nguyen, D Poshyvanyk, R Oliveto- arXiv preprint arXiv, 2025\nRecent progress in Large Language Models (LLMs) has substantially advanced the \nautomation of software engineering (SE) tasks, enabling complex activities such as \ncode generation and code summarization. However, the black-box nature of LLMs", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.20328&hl=vi&sa=X&d=18107533920722513838&ei=A_tPaZjXEqC16rQPm4fPgQQ&scisig=ALhkC2RhBFqRcXhcOQIa56u5R1bE&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ALhkC2T2gGOcVPTEcMFcARghNUJN&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "VDMPAGR: A vulnerability detection model based on pointer analysis and graph representation", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Graph"], "data": "Y Dong, S Liu, X Liu, M Chen, S Wang, Y Feng- Information and Software, 2025\nContext: Software vulnerabilities pose a major threat to software security. Deep \nlearning-based vulnerability detection models have demonstrated notable \nadvantages, particularly in terms of automation and accuracy. Among these, graph", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950584925003210&hl=vi&sa=X&d=558143430722896337&ei=A_tPaZjXEqC16rQPm4fPgQQ&scisig=ALhkC2Q-zlQbenNHcC1nYe1IeGcP&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ALhkC2T2gGOcVPTEcMFcARghNUJN&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Tuning LLM in secure code generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "DS Shaikhelislamov, MS Varetsa, AS Syomkin-  , 2025\nThe popularity of using LLM for code generation makes it mandatory to \ncomprehensively verify the security and reliability of the generated code. To verify the \ngenerated code, it is suggested to use the static analyzer Svace, which checks the\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://www.mathnet.ru/rus/tisp1045&hl=vi&sa=X&d=5765086413756448946&ei=A_tPaZjXEqC16rQPm4fPgQQ&scisig=ALhkC2RNVNU28flijldY4h73JER0&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ALhkC2T2gGOcVPTEcMFcARghNUJN&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "CodeQUEST: Evaluation and improvement of code quality using LLMs", "first_label": ["LLM", "Code"], "second_label": [], "data": "R Liu, A Frade, A Vaidya, M Labonne, M Kaiser- feedback\nThis paper presents CodeQUEST, an innovative framework leveraging Large \nLanguage Models (LLMs) to iteratively assess and enhance code quality across \nvarious dimensions, adhering to software engineering best practices. CodeQUEST \nconsists of two main components: the Evaluator, which provides quantitative scores \nand qualitative summaries to assess code quality, and the Optimizer, which refines \nthe code iteratively based on Evaluator feedback. Applying CodeQUEST to a curated\nTrch dn: Thanh Le-Cong, Ratnadira Widyasari, Chakkrit Tantithamthavorn\u00a0\u00a0\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng li trch dn mi trong cc bi vit ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/11262267/11262260/11262341.pdf&hl=vi&sa=X&d=18025768571059995662&ei=JphOadiqEL2qieoPuKej0QM&scisig=ALhkC2Ts5PThyDwRNIT4NP4WCG2c&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:ALhkC2S5kr7kHUQq0DGLL-ZCgBVB&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["1 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "Semantically-Equivalent Transformations-Based Backdoor Attacks against Neural Code Models: Characterization and Mitigation", "first_label": ["Code"], "second_label": [], "data": "J Ye, Z Li, X Tang, S Xu, D Zou, Z Yuan- arXiv preprint arXiv:2512.19215, 2025\nNeural code models have been increasingly incorporated into software development \nprocesses. However, their susceptibility to backdoor attacks presents a significant \nsecurity risk. The state-of-the-art understanding focuses on injection-based attacks", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.19215&hl=vi&sa=X&d=314251472644159945&ei=JphOab3pBKyK6rQPgZOO6A8&scisig=ALhkC2Sk6MpjUIqa1Vmb2oDUeL0Q&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ALhkC2T2gGOcVPTEcMFcARghNUJN&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "SoK: Understanding (New) Security Issues Across AI4Code Use Cases", "first_label": ["Code"], "second_label": [], "data": "Q Wu, T Li, T Zhou, V Chandrasekaran- arXiv preprint arXiv:2512.18456, 2025\nAI-for-Code (AI4Code) systems are reshaping software engineering, with tools like \nGitHub Copilot accelerating code generation, translation, and vulnerability detection. \nAlongside these advances, however, security risks remain pervasive: insecure\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.18456&hl=vi&sa=X&d=4185099855072980047&ei=JphOab3pBKyK6rQPgZOO6A8&scisig=ALhkC2Tc5fAeQob4XnH-JnfYgGW1&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ALhkC2T2gGOcVPTEcMFcARghNUJN&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
