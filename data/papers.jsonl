{"title": "LLM-based Vulnerability Discovery through the Lens of Code Metrics", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": [], "data": "F Weissberg, L Pirch, E Imgrund, J Mller, T Eisenhofer- arXiv preprint arXiv, 2025\nLarge language models (LLMs) excel in many tasks of software engineering, yet \nprogress in leveraging them for vulnerability discovery has stalled in recent years. To \nunderstand this phenomenon, we investigate LLMs through the lens of classic code", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.19117&hl=vi&sa=X&d=9123199236929215814&ei=Uq3XaKHOCNq06rQPy6vVkAI&scisig=AAZF9b9NYfbk81y_m-4rkRbLeJNM&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "On the Soundness and Consistency of LLM Agents for Executing Test Cases Written in Natural Language", "first_label": ["LLM", "Software Testing"], "second_label": ["Agent"], "data": "S Salva, R Taguelmimt- arXiv preprint arXiv:2509.19136, 2025\nThe use of natural language (NL) test cases for validating graphical user interface \n(GUI) applications is emerging as a promising direction to manually written \nexecutable test scripts, which are costly to develop and difficult to maintain. Recent", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.19136&hl=vi&sa=X&d=14763218273592887225&ei=Uq3XaKHOCNq06rQPy6vVkAI&scisig=AAZF9b-UHW8cguy7BjMGIC6z7CK9&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Benchmarking and Studying the LLM-based Code Review", "first_label": ["LLM", "Code Review", "Code"], "second_label": [], "data": "Z Zeng, R Shi, K Han, Y Li, K Sun, Y Wang, Z Yu, R Xie- arXiv preprint arXiv, 2025\nAutomated Code Review (ACR) is crucial for software quality, yet existing \nbenchmarks often fail to reflect real-world complexities, hindering the evaluation of \nmodern Large Language Models (LLMs). Current benchmarks frequently focus on", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01494&hl=vi&sa=X&d=9924101107475937857&ei=Uq3XaKHOCNq06rQPy6vVkAI&scisig=AAZF9b9CW-Ez1-ukRHGu-p7F6_IT&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "first_label": ["LLM"], "second_label": ["Agent"], "data": "T Lindenbauer, I Slinko, L Felder, E Bogomolov- arXiv preprint arXiv, 2025\nLarge Language Model (LLM)-based agents solve complex tasks through iterative \nreasoning, exploration, and tool-use, a process that can result in long, expensive \ncontext histories. While state-of-the-art Software Engineering (SE) agents like\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.21433&hl=vi&sa=X&d=3778813371369713554&ei=Uq3XaKHOCNq06rQPy6vVkAI&scisig=AAZF9b8vjKgLLO8JtQg2HjxwaIIj&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Toward efficient vibe coding: An LLM-based agent for low-code software development", "first_label": ["LLM", "Code"], "second_label": ["Agent"], "data": "N Malamas, E Tsardoulias, K Panayiotou- Journal of Computer, 2025\nAbstract The Software Engineering (SE) domain increasingly adopts low-code and \nno-code approaches to simplify application development and deployment. Two \ndominant paradigms have emerged in this space: Model-driven Engineering (MDE), \nleveraging Domain-specific Languages (DSLs) to abstract implementation and \nreduce the knowledge and expertise required, and LLM-based vibe coding, where \ndevelopers interact with Large Language Models (LLMs) using natural language\nTrch dn: Refining chatgpt-generated code: Characterizing and mitigating\u00a0\u00a0\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng li trch dn mi trong cc bi vit ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S259011842500053X&hl=vi&sa=X&d=14193155343073234717&ei=Uq3XaMibFJXP6rQPo4LniQU&scisig=AAZF9b-LMPQ2q6J-9eobpharqYge&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:AAZF9b-KfaIzNELg_AxYHyYLV6lH&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["1 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
