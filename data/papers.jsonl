{"title": "Wisdom and Delusion of LLM Ensembles for Code Generation and Repair", "first_label": ["LLM", "Code"], "second_label": ["Repair", "Generation"], "data": "F Vallecillos-Ruiz, M Hort, L Moonen- arXiv preprint arXiv:2510.21513, 2025\nToday's pursuit of a single Large Language Model (LMM) for all software \nengineering tasks is resource-intensive and overlooks the potential benefits of \ncomplementarity, where different models contribute unique strengths. However, the", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.21513&hl=vi&sa=X&d=7414273881583577151&ei=KDkKaaqCGOSv6rQPh5K9yQ8&scisig=ABGrvjJze_Gfx9_06SAKA-BlHAZz&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Vul-R2: A Reasoning LLM for Automated Vulnerability Repair", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Repair", "Reasoning"], "data": "XC Wen, Z Lin, Y Yang, C Gao, D Ye- arXiv preprint arXiv:2510.05480, 2025\nThe exponential increase in software vulnerabilities has created an urgent need for \nautomatic vulnerability repair (AVR) solutions. Recent research has formulated AVR \nas a sequence generation problem and has leveraged large language models", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.05480&hl=vi&sa=X&d=17087307418542281791&ei=KDkKaaqCGOSv6rQPh5K9yQ8&scisig=ABGrvjJlsQcjOBCSZutD9pRzL3u0&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "SemOpt: LLM-Driven Code Optimization via Rule-Based Analysis", "first_label": ["LLM", "Code"], "second_label": [], "data": "Y Zhao, YA Xiao, Q Xiao, Z Zhang, Y Xiong- arXiv preprint arXiv:2510.16384, 2025\nAutomated code optimization aims to improve performance in programs by \nrefactoring code, and recent studies focus on utilizing LLMs for the optimization. \nTypical existing approaches mine optimization commits from open-source", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.16384&hl=vi&sa=X&d=17733183336457524325&ei=KDkKaaqCGOSv6rQPh5K9yQ8&scisig=ABGrvjIdTJLV1wH4Tm1656yfT86T&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "SecureReviewer: Enhancing Large Language Models for Secure Code Review through Secure-aware Fine-tuning", "first_label": ["LLM", "Code Review", "Code"], "second_label": [], "data": "F Liu, S Liu, Y Zhu, X Lian, L Zhang- arXiv preprint arXiv:2510.26457, 2025\nIdentifying and addressing security issues during the early phase of the development \nlifecycle is critical for mitigating the long-term negative impacts on software systems. \nCode review serves as an effective practice that enables developers to check their", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.26457&hl=vi&sa=X&d=2750772061662092214&ei=KDkKaaqCGOSv6rQPh5K9yQ8&scisig=ABGrvjJCIQLgS8ShLO-ChXzeoUuk&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Source Code Guardrail: AI Driven Solution to Distinguish Critical vs. Generic Code for Enterprise LLM Security", "first_label": ["LLM", "Code"], "second_label": [], "data": "R Sharma, A Gupta- International Conference on Provable Security, 2025\nAbstract The adoption of Large Language Models (LLMs) in businesses raises the \npossibility of inadvertent intellectual property (IP) and secret data leaks to public \nartificial intelligence systems. Organizations are using security solutions, including", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-95-2961-2_23&hl=vi&sa=X&d=5184326828152072441&ei=KDkKaaqCGOSv6rQPh5K9yQ8&scisig=ABGrvjJOJG-OQ4wH-x-OhS5wRNe2&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "MirrorFuzz: Leveraging LLM and Shared Bugs for Deep Learning Framework APIs Fuzzing", "first_label": ["LLM", "Fuzzing", "Bug"], "second_label": [], "data": "S Ou, Y Li, L Yu, C Wei, T Wen, Q Chen, Y Chen- IEEE Transactions on, 2025\nDeep learning (DL) frameworks serve as the backbone for a wide range of artificial \nintelligence applications. However, bugs within DL frameworks can cascade into \ncritical issues in higher-level applications, jeopardizing reliability and security. While", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/32/4359463/11201027.pdf&hl=vi&sa=X&d=1422528139240657868&ei=KDkKaaqCGOSv6rQPh5K9yQ8&scisig=ABGrvjI1tTlw2XwsJvzcyylBVxMq&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "TIT: A Tree-Structured Instruction Tuning Approach for LLM-Based Code Translation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "H Jiang, Y Wang, H Lin, P Zou, Z Zhou, A Jia, X Li- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) have shown strong performance in automated \nsource-to-target code translation through pretraining on extensive code corpora. \nHowever, mainstream LLM-based code translation methods suffer from two critical", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.09400&hl=vi&sa=X&d=13736189209612319180&ei=KDkKaaqCGOSv6rQPh5K9yQ8&scisig=ABGrvjLfQpVO1yEU3BC2VHg0FKp1&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Enhancing LLM's Ability to Generate More Repository-Aware Unit Tests Through Precise Context Injection", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "X Yin, C Ni, X Li, L Chen, G Ma, X Yang\nRecently, Large Language Models (LLMs) have gained attention for their ability to \nhandle a broad range of tasks, including unit test generation. Despite their success, \nLLMs may exhibit hallucinations when generating unit tests for focal methods or", "link": "https://scholar.google.com/scholar_url?url=https://vinci-grape.github.io/papers/Enhancing_LLM_s_Ability_to_Generate_More_Repository_Aware_Unit_Tests_Through_Precise_Context_Injection.pdf&hl=vi&sa=X&d=3506872574868649515&ei=KDkKaaqCGOSv6rQPh5K9yQ8&scisig=ABGrvjKPA0zq2FXS1WyPoCr65qwT&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=7&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Adaptive Proof Refinement with LLM-Guided Strategy Selection", "first_label": ["LLM"], "second_label": [], "data": "M Lu, Z Zhou, D Xie, S Jia, B Delaware, T Zhang- arXiv preprint arXiv:2510.25103, 2025\nFormal verification via theorem proving enables the expressive specification and \nrigorous proof of software correctness, but it is difficult to scale due to the significant \nmanual effort and expertise required. While Large Language Models (LLMs) show", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.25103&hl=vi&sa=X&d=5975204416659974907&ei=KDkKaaqCGOSv6rQPh5K9yQ8&scisig=ABGrvjKkxpZfzPdYuZ4UtGP1F_PP&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=8&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Understanding LLM-Driven Test Oracle Generation", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "A Bodicoat, G Jahangirova, V Terragni\nAutomated unit test generation aims to improve software quality while reducing the \ntime and effort required for creating tests manually. However, existing techniques \nprimarily generate regression oracles that predicate on the implemented behavior of\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Valerio-Terragni/publication/397039765_Understanding_LLM-Driven_Test_Oracle_Generation/links/6902c057c900be105cbdb064/Understanding-LLM-Driven-Test-Oracle-Generation.pdf&hl=vi&sa=X&d=12097821390559666401&ei=KDkKaaqCGOSv6rQPh5K9yQ8&scisig=ABGrvjIXkDwyMD9hFiuIe4cSDy3c&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=9&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Is Your Prompt Poisoning Code? Defect Induction Rates and Security Mitigation Strategies", "first_label": ["Code", "Software Defect"], "second_label": [], "data": "B Wang, YL Zhong, MD Wan, WJ Yu, YB Ouyang- arXiv preprint arXiv, 2025\nLarge language models (LLMs) have become indispensable for automated code \ngeneration, yet the quality and security of their outputs remain a critical concern. \nExisting studies predominantly concentrate on adversarial attacks or inherent flaws \nwithin the models. However, a more prevalent yet underexplored issue concerns \nhow the quality of a benign but poorly formulated prompt affects the security of the \ngenerated code. To investigate this, we first propose an evaluation framework for\nTrch dn: Refining chatgpt-generated code: Characterizing and mitigating\u00a0\u00a0\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng li trch dn mi trong cc bi vit ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.22944&hl=vi&sa=X&d=14215146240991081594&ei=KDkKaealJMHO6rQPjanaqAg&scisig=ABGrvjJhefshV2c262vq2lsz1aMv&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:ABGrvjL2eoLgrMchC3yPzCtO9Gb4&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["1 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "Triangle: Empowering Incident Triage with Multi-LLM-Agents", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Z YU, M MA, X FENG, R DING, Z CHAOYUN - 2025\nAs shown in Figure 1, a customer reported incident highlights a sign-in issue \nencountered by a service client on Mac devices. Initially, the incident is manually \ntriaged to Team A, who attempt to resolve the issue through various steps, but are \nultimately unable to fix it. Consequently, the incident is transferred to Team B based \non their domain knowledge. Team B follows their troubleshooting guide (TSG), \nconducts further examinations, but still does not resolve the problem, leading them to\nTrch dn: Leveraging large language model for automatic patch correctness\u00a0\u00a0\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng li trch dn mi trong cc bi vit ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://netman.aiops.org/wp-content/uploads/2025/10/TRIANGLE_FSE25.pdf&hl=vi&sa=X&d=2260585892941165037&ei=jmwIabSCGv-j6rQP4cHB4A4&scisig=ABGrvjIUASmjZG3uDHGQH5niAjkk&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:ABGrvjL2eoLgrMchC3yPzCtO9Gb4&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["1 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "Automated Program Repair Based on REST API Specifications Using Large Language Models", "first_label": ["APR", "LLM"], "second_label": ["Repair"], "data": "K Yamagishi, N Yoshida, E Makihara, K Inoue- arXiv preprint arXiv:2510.25148, 2025\nMany cloud services provide REST API accessible to client applications. However, \ndevelopers often identify specification violations only during testing, as error \nmessages typically lack the detail necessary for effective diagnosis. Consequently", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.25148&hl=vi&sa=X&d=6401658396552067105&ei=jmwIabqaDYGpieoP_8jXuAM&scisig=ABGrvjKZiX-k5tx0TL-AAUGOqhM5&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Beyond Synthetic Benchmarks: Evaluating LLM Performance on Real-World Class-Level Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "M Rahman, SH Khatoonabadi, E Shihab- arXiv preprint arXiv:2510.26130, 2025\nLarge language models (LLMs) have advanced code generation at the function \nlevel, yet their ability to produce correct class-level implementations in authentic \nsoftware projects remains poorly understood. This work introduces a novel\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/abs/2510.26130&hl=vi&sa=X&d=13761241531887805841&ei=jmwIabqaDYGpieoP_8jXuAM&scisig=ABGrvjKaBxwIwCBeEmF0Zk7fVj4_&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
