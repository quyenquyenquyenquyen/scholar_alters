{"title": "Human-Written vs. AI-Generated Code: A Large-Scale Study of Defects, Vulnerabilities, and Complexity", "first_label": ["Vulnerabilities", "Code", "Software Defect"], "second_label": [], "data": "D Cotroneo, C Improta, P Liguori- arXiv preprint arXiv:2508.21634, 2025\nAs AI code assistants become increasingly integrated into software development \nworkflows, understanding how their code compares to human-written programs is \ncritical for ensuring reliability, maintainability, and security. In this paper, we present \na large-scale comparison of code authored by human developers and three state-of-\nthe-art LLMs, ie, ChatGPT, DeepSeek-Coder, and Qwen-Coder, on multiple \ndimensions of software quality: code defects, security vulnerabilities, and structural\nTrch dn: Refining chatgpt-generated code: Characterizing and mitigating", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.21634&hl=vi&sa=X&d=8477581447837533475&ei=o_K8aKqzMefYieoP5s7t2Qo&scisig=AAZF9b-M9zrl_2Ouj3ipW3Ds0IQb&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:AAZF9b-KfaIzNELg_AxYHyYLV6lH&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["2 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "Avaliao comparativa do desempenho de inteligncias artificiais generativas e ferramentas tradicionais na anlise de cdigo-fonte JavaScript", "first_label": [], "second_label": [], "data": "R Pimentel, CB Progetti- Simpsio Brasileiro de Segurana da Informao e de, 2025\nEstudo comparativo entre ferramentas SAST (Semgrep/SonarQube) e modelos LLM \n(DeepSeek/CodeLlama) na deteco de vulnerabilidades em JavaScript (OWASP \nJuice Shop). Resultados revelam complementaridade: SASTs alcanam 100% de \npreciso para vulnerabilidades padro (XSS/SQLi), enquanto LLMs oferecem maior \nrecall (70% no DeepSeek) para ameaas contextuais (NoSQLi/Broken Access \nControl). A taxa de 22-45% de falsos positivos em LLMs demanda estratgias de\nTrch dn: Comparison of static application security testing tools and large\u00a0\u00a0\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng li trch dn mi trong cc bi vit ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://sol.sbc.org.br/index.php/sbseg_estendido/article/download/36756/36542/&hl=vi&sa=X&d=11971438696651862258&ei=o_K8aKqzMefYieoP5s7t2Qo&scisig=AAZF9b8NSgOQNe0ibg7Gi2jABLp4&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:AAZF9b-KfaIzNELg_AxYHyYLV6lH&html=&pos=1&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["2 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "Automated Repair of C Programs Using Large Language Models", "first_label": ["APR", "LLM"], "second_label": ["Repair"], "data": "M Farzandway, F Ghassemi- arXiv preprint arXiv:2509.01947, 2025\nThis study explores the potential of Large Language Models (LLMs) in automating \nthe repair of C programs. We present a framework that integrates spectrum-based \nfault localization (SBFL), runtime feedback, and Chain-of-Thought-structured", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01947&hl=vi&sa=X&d=1317846922093490120&ei=o_K8aJjVJffP6rQP2-GA-Qo&scisig=AAZF9b9xJ1n4DpSkY2MDDEUWo_Wk&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "An Empirical Study of Vulnerable Package Dependencies in LLM Repositories", "first_label": ["LLM"], "second_label": [], "data": "S Liu, X Hu, X Xia, D Lo, X Yang- arXiv preprint arXiv:2508.21417, 2025\nLarge language models (LLMs) have developed rapidly in recent years, \nrevolutionizing various fields. Despite their widespread success, LLMs heavily rely \non external code dependencies from package management systems, creating a", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.21417&hl=vi&sa=X&d=14553577615445056080&ei=o_K8aJjVJffP6rQP2-GA-Qo&scisig=AAZF9b9j862ZVwGt7jgVb2PyU_Ih&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Benchmarking and Studying the LLM-based Code Review", "first_label": ["LLM", "Code Review", "Code"], "second_label": [], "data": "Z Zeng, R Shi, K Han, Y Li, K Sun, Y Wang, Z Yu, R Xie- arXiv preprint arXiv, 2025\nAutomated Code Review (ACR) is crucial for software quality, yet existing \nbenchmarks often fail to reflect real-world complexities, hindering the evaluation of \nmodern Large Language Models (LLMs). Current benchmarks frequently focus on", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01494&hl=vi&sa=X&d=9924101107475937857&ei=o_K8aJjVJffP6rQP2-GA-Qo&scisig=AAZF9b9CW-Ez1-ukRHGu-p7F6_IT&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "ChopChop: a Programmable Framework for Semantically Constraining the Output of Language Models", "first_label": ["LLM"], "second_label": [], "data": "S Nagy, T Zhou, N Polikarpova, L D'Antoni- arXiv preprint arXiv:2509.00360, 2025\nLanguage models (LMs) can generate code, but cannot guarantee its correctness--\nproducing outputs that often violate type safety, program invariants, or semantic \nequivalence. Constrained decoding offers a solution by restricting generation to", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.00360&hl=vi&sa=X&d=15761961036894749958&ei=o_K8aJjVJffP6rQP2-GA-Qo&scisig=AAZF9b9gFg_U0FktMXuQ5DX2sTxT&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "LLM-Based Program Generation for Triggering Numerical Inconsistencies Across Compilers", "first_label": ["LLM"], "second_label": ["Generation"], "data": "Y Wang, C Rubio-Gonzlez- arXiv preprint arXiv:2509.00256, 2025\nFloating-point inconsistencies across compilers can undermine the reliability of \nnumerical software. We present LLM4FP, the first framework that uses Large \nLanguage Models (LLMs) to generate floating-point programs specifically designed", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.00256&hl=vi&sa=X&d=6362971429469914313&ei=o_K8aJjVJffP6rQP2-GA-Qo&scisig=AAZF9b_4FT9ZnZeCMwHPUqYhSw9g&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Token Sugar: Making Source Code Sweeter for LLMs through Token-Efficient Shorthand", "first_label": ["LLM", "Code"], "second_label": [], "data": "Z Sun, C Yang, X Du, Z Yang, L Li, D Lo\nLarge language models (LLMs) have shown exceptional performance in code \ngeneration and understanding tasks, yet their high computational costs hinder \nbroader adoption. One important factor is the inherent verbosity of programming\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://v587su.github.io/papers/SugarPaper.pdf&hl=vi&sa=X&d=10071555566761971863&ei=o_K8aJjVJffP6rQP2-GA-Qo&scisig=AAZF9b_FQtP2qw0czwy-pXoKQTUa&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:AAZF9b-46FvMQTpOKclK0XMbpLrW&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
