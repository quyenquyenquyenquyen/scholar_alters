{"title": "Large Language Models for Code Translation: An In-Depth Analysis of Code Smells and Functional Correctness", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "C Feischl, R Kern- ACM Transactions on Software Engineering and, 2025\nThe conversion of program code from a given source programming language (PL) to \nanother target PL is known as code translation, and has a wide applicability. Since \nLarge Language Models (LLMs) have shown remarkable performance across \ndifferent application fields, research considers LLMs to mitigate shortcomings of \ntraditional approaches in code translation. However, existing literature mainly \nfocuses on code correctness and falls short of an investigation of the resulting code\nTrch dn: Thanh Le-Cong, Ratnadira Widyasari, Chakkrit Tantithamthavorn", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3777383&hl=vi&sa=X&d=18446479103686779826&ei=oNIjafqwDNOyieoPyofJ-QE&scisig=ABGrvjKpvRr4Stx0CrI5YwWsgVYy&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:ABGrvjL2eoLgrMchC3yPzCtO9Gb4&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["5 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "What characteristics make ChatGPT effective for software issue resolution? An empirical study of task, project, and conversational signals in GitHub issues", "first_label": ["LLM", "GitHub Issue"], "second_label": [], "data": "R Ehsani, S Pathak, E Parra, S Haiduc, P Chatterjee- Empirical Software, 2026\nConversational large-language models (LLMs), such as ChatGPT, are extensively \nused for issue resolution tasks, particularly for generating ideas to implement new \nfeatures or resolve bugs. However, not all developer-LLM conversations are useful \nfor effective issue resolution and it is still unknown what makes some of these \nconversations not helpful. In this paper, we analyze 686 developer-ChatGPT \nconversations shared within GitHub issue threads to identify characteristics that\nTrch dn: Are we ready to embrace generative ai for software q&a?", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10664-025-10745-8&hl=vi&sa=X&d=8469108112663412553&ei=oNIjafqwDNOyieoPyofJ-QE&scisig=ABGrvjJhBRQ0tik4wK78zfOOH0kk&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:ABGrvjL2eoLgrMchC3yPzCtO9Gb4&html=&pos=1&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["5 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "How did the Emergence of ChatGPT Impact Stack Overflow?A Literature Review", "first_label": ["LLM"], "second_label": [], "data": "D Staegemann, M Rizun, C Haertel, M Pohl, C Daase - 2025\nAs a consequence of ChatGPT's public release in 2022, software developers and \nlearners of the profession were suddenly provided with a completely new and \npotentially extremely powerful tool to support them in designing and implementing \ntheir applications and answering occurring topic related questions. While, previously, \ncommunity driven question and answer platforms like Stack Overflow were \nsomewhat unique in their value proposition by providing (the chance for) answers\nTrch dn: Are we ready to embrace generative ai for software q&a?", "link": "https://scholar.google.com/scholar_url?url=https://aisel.aisnet.org/isd2014/proceedings2025/agile/10/&hl=vi&sa=X&d=18141301467186017273&ei=oNIjafqwDNOyieoPyofJ-QE&scisig=ABGrvjLWbniQdygWpYQpkDL1dlQB&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:ABGrvjL2eoLgrMchC3yPzCtO9Gb4&html=&pos=2&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["5 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "Quality Assurance in Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "D Song - 2025\nAbstract Large Language Models (LLMs) have demonstrated impressive capabilities \nacross a wide range of tasks in natural language processing (NLP) and software \nengineering (SE). However, their increasing adoption has raised critical concerns \nabout trustworthiness, including robustness under distribution shifts, vulnerability to \nhallucinations, and misalignment between confidence and accuracy. These issues \nare exacerbated by the complex and probabilistic nature of LLMs, which makes it\nTrch dn: Refining chatgpt-generated code: Characterizing and mitigating", "link": "https://scholar.google.com/scholar_url?url=https://ualberta.scholaris.ca/bitstreams/182b82d1-f9e0-4e10-a493-6beba20a3db2/download&hl=vi&sa=X&d=9868273145291117306&ei=oNIjafqwDNOyieoPyofJ-QE&scisig=ABGrvjJrK-5eY9KKDuRB-ofR_gea&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:ABGrvjL2eoLgrMchC3yPzCtO9Gb4&html=&pos=3&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["5 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "Towards Quality Assurance for AI Software Systems", "first_label": [], "second_label": [], "data": "Z Wang - 2025\nOver the past decade, machine learning techniques have been significantly \nadvanced. As a result, software systems involving artificial intelligence (AI) \ncomponents (AI software systems) have become pervasive and widely deployed \nacross different domains and applications. Recent advancements in large language \nmodels (LLMs) and generative AI have further demonstrated the potential of AI in \nreshaping the software industry. Similar to any other traditional software systems, AI\nTrch dn: Refining chatgpt-generated code: Characterizing and mitigating\u00a0\u00a0\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng li trch dn mi trong cc bi vit ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://ualberta.scholaris.ca/bitstreams/037c6468-93e1-44b0-a6c3-24e121bfd00a/download&hl=vi&sa=X&d=5581163786966503791&ei=oNIjafqwDNOyieoPyofJ-QE&scisig=ABGrvjI3AzMABz2dtd956TxL7vB1&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:ABGrvjL2eoLgrMchC3yPzCtO9Gb4&html=&pos=4&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["5 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "A zero-shot framework for cross-project vulnerability detection in source code", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection"], "data": "R Haque, A Ali, S McClean, N Khan- Empirical Software Engineering, 2026\nThe growing prevalence of software vulnerabilities has increased the need for \neffective detection methods, particularly in cross-project settings where domain \ndifferences create significant challenges. Existing vulnerability detection models", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10664-025-10749-4&hl=vi&sa=X&d=5787044264909627309&ei=oNIjad_mAaG7ieoP8Y6WyQc&scisig=ABGrvjJ29zOgzha_sOP3xWytZM2T&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "LMFuzz: Program repair fuzzing based on large language models", "first_label": ["APR", "LLM", "Fuzzing"], "second_label": ["Repair"], "data": "R Lin, R Wang, G Hu, X Xu- Automated Software Engineering, 2026\nGenerating programs using large language models (LLMs) for fuzz testing has \nemerged as a significant testing methodology. While traditional fuzzers can produce \ncorrect programs, their effectiveness is limited by excessive constraints and restricted", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00568-8&hl=vi&sa=X&d=16706984066078411801&ei=oNIjad_mAaG7ieoP8Y6WyQc&scisig=ABGrvjLMTxGR3-Z1Hr556q7Ejx9K&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Beyond Synthetic Benchmarks: Evaluating LLM Performance on Real-World Class-Level Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "M Rahman, SH Khatoonabadi, E Shihab- arXiv preprint arXiv:2510.26130, 2025\nLarge language models (LLMs) have advanced code generation at the function \nlevel, yet their ability to produce correct class-level implementations in authentic \nsoftware projects remains poorly understood. This work introduces a novel", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.26130&hl=vi&sa=X&d=13761241531887805841&ei=oNIjad_mAaG7ieoP8Y6WyQc&scisig=ABGrvjLlYmn4XLej__SC0XdKrFFY&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "LoCoBench-Agent: An Interactive Benchmark for LLM Agents in Long-Context Software Engineering", "first_label": ["LLM"], "second_label": ["Agent"], "data": "J Qiu, Z Liu, Z Liu, R Murthy, J Zhang, H Chen, S Wang- arXiv preprint arXiv, 2025\nAs large language models (LLMs) evolve into sophisticated autonomous agents \ncapable of complex software development tasks, evaluating their real-world \ncapabilities becomes critical. While existing benchmarks like LoCoBench~\\cite", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.13998&hl=vi&sa=X&d=5068327394060475494&ei=oNIjad_mAaG7ieoP8Y6WyQc&scisig=ABGrvjK9zILMF-H5bmo_6Oj44-_r&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "CodeCrash: Exposing LLM Fragility to Misleading Natural Language in Code Reasoning", "first_label": ["LLM", "Code"], "second_label": ["Reasoning"], "data": "MH Lam, C Wang, J Huang, M Lyu- The Thirty-ninth Annual Conference on Neural\nLarge Language Models (LLMs) have recently demonstrated strong capabilities in \ncode-related tasks, but their robustness in code reasoning under perturbations \nremains underexplored. We introduce CodeCrash, a stress-testing framework with", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DCAB0EjD9EK&hl=vi&sa=X&d=13889957657119136301&ei=oNIjad_mAaG7ieoP8Y6WyQc&scisig=ABGrvjLDDoY0GiXO7mB3QF7Zpr9h&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "SecureReviewer: Enhancing Large Language Models for Secure Code Review through Secure-aware Fine-tuning", "first_label": ["LLM", "Code Review", "Code"], "second_label": [], "data": "F Liu, S Liu, Y Zhu, X Lian, L Zhang- arXiv preprint arXiv:2510.26457, 2025\nIdentifying and addressing security issues during the early phase of the development \nlifecycle is critical for mitigating the long-term negative impacts on software systems. \nCode review serves as an effective practice that enables developers to check their", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.26457&hl=vi&sa=X&d=2750772061662092214&ei=oNIjad_mAaG7ieoP8Y6WyQc&scisig=ABGrvjJCIQLgS8ShLO-ChXzeoUuk&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Preconditions and Postconditions as Design Constraints for LLM Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "L Newcomb, A Davidoff, O Ochoa- IEEE Access, 2025\nLarge Language Models (LLMs) have significantly advanced automated code \ngeneration, but current methods predominantly rely on natural language descriptions \nduring prompting. This approach encounters challenges when handling complex", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/10820123/11218044.pdf&hl=vi&sa=X&d=2337714649732748995&ei=oNIjad_mAaG7ieoP8Y6WyQc&scisig=ABGrvjJOfei8fbkAtS9augPuYsaC&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "KTester: Leveraging Domain and Testing Knowledge for More Effective LLM-based Test Generation", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "A Li, M Liu, Z Chen, Z Pei, Z Li, D Dai, Y Wang, Z Zheng- arXiv preprint arXiv, 2025\nAutomated unit test generation using large language models (LLMs) holds great \npromise but often struggles with generating tests that are both correct and \nmaintainable in real-world projects. This paper presents KTester, a novel framework", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.14224&hl=vi&sa=X&d=10983934054869938261&ei=oNIjad_mAaG7ieoP8Y6WyQc&scisig=ABGrvjIa1vtPoJYgQBH-oUV-iEOl&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=7&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "SAINT: Service-level Integration Test Generation with Program Analysis and LLM-based Agents", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation", "Agent"], "data": "R Pan, R Pavuluri, R Huang, R Krishna, T Stennett- arXiv preprint arXiv, 2025\nEnterprise applications are typically tested at multiple levels, with service-level \ntesting playing an important role in validating application functionality. Existing \nservice-level testing tools, especially for RESTful APIs, often employ fuzzing and/or", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.13305&hl=vi&sa=X&d=9022492230427322452&ei=oNIjad_mAaG7ieoP8Y6WyQc&scisig=ABGrvjIMsS1xc9Zre8DmeA3ZJSCx&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=8&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Coverage-Based Harmfulness Testing for LLM Code Transformation", "first_label": ["LLM", "Code", "Software Testing"], "second_label": [], "data": "H Tan, H Wang, D Pressato, Y Xu, SH Tan\nHarmful content embedded in program elements within source code may have \ndetrimental impact on mental health of software developers, and promote harmful \nbehavior. Our key insight is that software developers may introduce harmful content\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://www.shinhwei.com/HarmfulnessTestingASE.pdf&hl=vi&sa=X&d=3477573746713553799&ei=oNIjad_mAaG7ieoP8Y6WyQc&scisig=ABGrvjJDTN0Mk1UOA2rBuCbdW6Ih&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=9&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
