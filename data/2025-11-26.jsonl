{"title": "A Metamorphic Testing Perspective on Knowledge Distillation for Language Models of Code: Does the Student Deeply Mimic the Teacher?", "first_label": ["LLM", "Code", "Software Testing"], "second_label": [], "data": "MA Awal, M Rochan, CK Roy- arXiv preprint arXiv:2511.05476, 2025\nTransformer-based language models of code have achieved state-of-the-art \nperformance across a wide range of software analytics tasks, but their practical \ndeployment remains limited due to high computational costs, slow inference speeds", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.05476&hl=vi&sa=X&d=696254596676747652&ei=ijUlafGTIdOyieoPyofJ-QE&scisig=ABGrvjK_Q2aL1u4_vrBbTDSTX8GZ&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "EDIT-Bench: Evaluating LLM Abilities to Perform Real-World Instructed Code Edits", "first_label": ["LLM", "Code"], "second_label": [], "data": "W Chi, V Chen, R Shar, A Mittal, J Liang, WL Chiang- arXiv preprint arXiv, 2025\nInstructed code editing, where LLMs directly modify a developer's existing code \nbased on a user instruction, is becoming a widely used interaction mode in AI coding \nassistants. However, few benchmarks directly evaluate this capability and current", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.04486&hl=vi&sa=X&d=5283698315003684171&ei=ijUlafGTIdOyieoPyofJ-QE&scisig=ABGrvjKwOFDZztr52wE5TC4Cj2cm&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "MonoEmbed: Enhancing LLM representations for monolith to microservices decomposition through contrastive learning", "first_label": ["LLM"], "second_label": [], "data": "K Sellami, MA Saied- Empirical Software Engineering, 2026\nAs Monolithic applications evolve, they become increasingly difficult to maintain and \nimprove, leading to scaling and organizational issues. The Microservices \narchitecture, known for its modularity, flexibility and scalability, offers a solution for", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10664-025-10732-z&hl=vi&sa=X&d=8063920521906541806&ei=ijUlafGTIdOyieoPyofJ-QE&scisig=ABGrvjLmQRs92VLTYJdMXzRogB81&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Explainable C/C++ vulnerability detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "Z Huang, A Aumpansub, S Shaik- International Journal of Information and Computer, 2025\nDetecting software vulnerabilities in C/C++ code is critical for ensuring software \nsecurity. In this paper, we explore the use of neural networks to detect vulnerabilities \nusing program slices that capture syntactic and semantic information. Our approach", "link": "https://scholar.google.com/scholar_url?url=https://www.inderscienceonline.com/doi/abs/10.1504/IJICS.2025.149450&hl=vi&sa=X&d=12504716210657107610&ei=ijUlafGTIdOyieoPyofJ-QE&scisig=ABGrvjLxTLHmo9J8CERFG-O46xNw&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "LLM For Loop Invariant Generation and Fixing: How Far Are We?", "first_label": ["LLM"], "second_label": ["Generation"], "data": "MR Akhond, S Chakraborty, G Uddin- arXiv preprint arXiv:2511.06552, 2025\nA loop invariant is a property of a loop that remains true before and after each \nexecution of the loop. The identification of loop invariants is a critical step to support \nautomated program safety assessment. Recent advancements in Large Language", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.06552&hl=vi&sa=X&d=3345853465015433439&ei=ijUlafGTIdOyieoPyofJ-QE&scisig=ABGrvjJkiz_XOQrivb4gEqihy63o&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "LLM4FP: LLM-Based Program Generation for Triggering Floating-Point Inconsistencies Across Compilers", "first_label": ["LLM"], "second_label": ["Generation"], "data": "Y Wang, C Rubio-Gonzlez- Proceedings of the SC'25 Workshops of the, 2025\nFloating-point inconsistencies across compilers can undermine the reliability of \nnumerical software. We present llm4fp, the first framework that uses Large Language \nModels (LLMs) to generate floating-point programs specifically designed to trigger", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3731599.3767362&hl=vi&sa=X&d=10536307710280011876&ei=ijUlafGTIdOyieoPyofJ-QE&scisig=ABGrvjImt4OQrJS_fSDAkEpo9-c9&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "IR-OptSet: An Optimization-Sensitive Dataset for Advancing LLM-Based IR Optimizer", "first_label": ["LLM"], "second_label": [], "data": "Z Yang, L Qiu, F Lyu, M Zhong, Z Chai, H Zhou, H Cui- The Thirty-ninth Annual\nCompiler optimization is essential for improving program performance, yet modern \ncompilers still depend on manually crafted transformation rules over intermediate \nrepresentations (IRs). As compilers grow in complexity, maintaining these rule-based\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DU8qonc6dMF&hl=vi&sa=X&d=8385962303449824386&ei=ijUlafGTIdOyieoPyofJ-QE&scisig=ABGrvjIRN94MWkpha-MTknkgoyTG&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "A Causal Perspective on Measuring, Explaining and Mitigating Smells in\\llm-Generated Code", "first_label": ["LLM", "Code"], "second_label": [], "data": "A Velasco, D Rodriguez-Cardenas, D Khati- arXiv preprint arXiv, 2025\nRecent advances in large language models (LLMs) have accelerated their adoption \nin software engineering contexts. However, concerns persist about the structural \nquality of the code they produce. In particular, LLMs often replicate poor coding \npractices, introducing code smells (ie, patterns that hinder readability, maintainability, \nor design integrity). Although prior research has examined the detection or repair of \nsmells, we still lack a clear understanding of how and when these issues emerge in\nTrch dn: Towards Reliable Evaluation of Neural Program Repair with", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.15817&hl=vi&sa=X&d=2515743366217550869&ei=ijUlae--MJvJieoPuauKkAw&scisig=ABGrvjKmxO-7CDwzhrh1_jLbvRPv&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:ABGrvjL2eoLgrMchC3yPzCtO9Gb4&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["3 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "CodeRankEval: Benchmarking and Analyzing LLM Performance for Code Ranking", "first_label": ["LLM", "Code"], "second_label": [], "data": "LG Chen, Z Xiao, YJ Xu, RC An, X Wang, YN Li, YH Li- Journal of Computer, 2025\nLarge language models (LLMs) are increasingly applied across diverse software \nengineering tasks. Consequently, their ability to effectively rank code quality is \ncrucial for applications like selecting optimal solutions and aiding code review. \nHowever, evaluating this essential code ranking capability is hampered by a lack of \nbenchmarks covering diverse paradigms and robustness testing. To address this, we \nintroduce CodeRankEval, a benchmark suite for multi-paradigm evaluation, and\nTrch dn: Refining chatgpt-generated code: Characterizing and mitigating", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s11390-025-5514-9&hl=vi&sa=X&d=3367816576857616045&ei=ijUlae--MJvJieoPuauKkAw&scisig=ABGrvjL_bvd-LmDo0IWENBqWU9g-&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:ABGrvjL2eoLgrMchC3yPzCtO9Gb4&html=&pos=1&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["3 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "GraMuS: Boosting Statement-level Fault Localization via Graph Representation and Multimodal Information", "first_label": ["Fault Localization"], "second_label": ["Localization", "Graph"], "data": "R Huang, B Yang, S Wu, Z Li, D Paul, XY Zhang- Journal of Systems and, 2025\nFault Localization (FL) aims to reduce the cost of manual debugging by highlighting \nthe statements which are more likely responsible for observed failures. However, \nexisting techniques have limited effectiveness in practice due to inflexible \nsuspiciousness evaluations and oversimplified representation of execution \ninformation. In this paper, we propose GraMuS, a novel Graph representation \nlearning and Multimodal information based technique for Statement-level FL\nTrch dn: FFL: Fine-grained fault localization for student programs via\u00a0\u00a0\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng li trch dn mi trong cc bi vit ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225003693&hl=vi&sa=X&d=6128707677741391442&ei=ijUlae--MJvJieoPuauKkAw&scisig=ABGrvjLf7G-tjj2xhtV5Le0TzsaF&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:ABGrvjL2eoLgrMchC3yPzCtO9Gb4&html=&pos=2&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["3 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "Large Language Models for Code Translation: An In-Depth Analysis of Code Smells and Functional Correctness", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "C Feischl, R Kern- ACM Transactions on Software Engineering and, 2025\nThe conversion of program code from a given source programming language (PL) to \nanother target PL is known as code translation, and has a wide applicability. Since \nLarge Language Models (LLMs) have shown remarkable performance across \ndifferent application fields, research considers LLMs to mitigate shortcomings of \ntraditional approaches in code translation. However, existing literature mainly \nfocuses on code correctness and falls short of an investigation of the resulting code\nTrch dn: Thanh Le-Cong, Ratnadira Widyasari, Chakkrit Tantithamthavorn", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3777383&hl=vi&sa=X&d=18446479103686779826&ei=oNIjafqwDNOyieoPyofJ-QE&scisig=ABGrvjKpvRr4Stx0CrI5YwWsgVYy&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:ABGrvjL2eoLgrMchC3yPzCtO9Gb4&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["5 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "What characteristics make ChatGPT effective for software issue resolution? An empirical study of task, project, and conversational signals in GitHub issues", "first_label": ["LLM", "GitHub Issue"], "second_label": [], "data": "R Ehsani, S Pathak, E Parra, S Haiduc, P Chatterjee- Empirical Software, 2026\nConversational large-language models (LLMs), such as ChatGPT, are extensively \nused for issue resolution tasks, particularly for generating ideas to implement new \nfeatures or resolve bugs. However, not all developer-LLM conversations are useful \nfor effective issue resolution and it is still unknown what makes some of these \nconversations not helpful. In this paper, we analyze 686 developer-ChatGPT \nconversations shared within GitHub issue threads to identify characteristics that\nTrch dn: Are we ready to embrace generative ai for software q&a?", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10664-025-10745-8&hl=vi&sa=X&d=8469108112663412553&ei=oNIjafqwDNOyieoPyofJ-QE&scisig=ABGrvjJhBRQ0tik4wK78zfOOH0kk&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:ABGrvjL2eoLgrMchC3yPzCtO9Gb4&html=&pos=1&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["5 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "How did the Emergence of ChatGPT Impact Stack Overflow?A Literature Review", "first_label": ["LLM"], "second_label": [], "data": "D Staegemann, M Rizun, C Haertel, M Pohl, C Daase - 2025\nAs a consequence of ChatGPT's public release in 2022, software developers and \nlearners of the profession were suddenly provided with a completely new and \npotentially extremely powerful tool to support them in designing and implementing \ntheir applications and answering occurring topic related questions. While, previously, \ncommunity driven question and answer platforms like Stack Overflow were \nsomewhat unique in their value proposition by providing (the chance for) answers\nTrch dn: Are we ready to embrace generative ai for software q&a?", "link": "https://scholar.google.com/scholar_url?url=https://aisel.aisnet.org/isd2014/proceedings2025/agile/10/&hl=vi&sa=X&d=18141301467186017273&ei=oNIjafqwDNOyieoPyofJ-QE&scisig=ABGrvjLWbniQdygWpYQpkDL1dlQB&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:ABGrvjL2eoLgrMchC3yPzCtO9Gb4&html=&pos=2&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["5 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "Quality Assurance in Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "D Song - 2025\nAbstract Large Language Models (LLMs) have demonstrated impressive capabilities \nacross a wide range of tasks in natural language processing (NLP) and software \nengineering (SE). However, their increasing adoption has raised critical concerns \nabout trustworthiness, including robustness under distribution shifts, vulnerability to \nhallucinations, and misalignment between confidence and accuracy. These issues \nare exacerbated by the complex and probabilistic nature of LLMs, which makes it\nTrch dn: Refining chatgpt-generated code: Characterizing and mitigating", "link": "https://scholar.google.com/scholar_url?url=https://ualberta.scholaris.ca/bitstreams/182b82d1-f9e0-4e10-a493-6beba20a3db2/download&hl=vi&sa=X&d=9868273145291117306&ei=oNIjafqwDNOyieoPyofJ-QE&scisig=ABGrvjJrK-5eY9KKDuRB-ofR_gea&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:ABGrvjL2eoLgrMchC3yPzCtO9Gb4&html=&pos=3&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["5 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "Towards Quality Assurance for AI Software Systems", "first_label": [], "second_label": [], "data": "Z Wang - 2025\nOver the past decade, machine learning techniques have been significantly \nadvanced. As a result, software systems involving artificial intelligence (AI) \ncomponents (AI software systems) have become pervasive and widely deployed \nacross different domains and applications. Recent advancements in large language \nmodels (LLMs) and generative AI have further demonstrated the potential of AI in \nreshaping the software industry. Similar to any other traditional software systems, AI\nTrch dn: Refining chatgpt-generated code: Characterizing and mitigating\u00a0\u00a0\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng li trch dn mi trong cc bi vit ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://ualberta.scholaris.ca/bitstreams/037c6468-93e1-44b0-a6c3-24e121bfd00a/download&hl=vi&sa=X&d=5581163786966503791&ei=oNIjafqwDNOyieoPyofJ-QE&scisig=ABGrvjI3AzMABz2dtd956TxL7vB1&oi=scholaralrt&hist=70gU4M0AAAAJ:6246953642887790424:ABGrvjL2eoLgrMchC3yPzCtO9Gb4&html=&pos=4&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["5 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Thanh Le-Cong"]}
{"title": "A zero-shot framework for cross-project vulnerability detection in source code", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection"], "data": "R Haque, A Ali, S McClean, N Khan- Empirical Software Engineering, 2026\nThe growing prevalence of software vulnerabilities has increased the need for \neffective detection methods, particularly in cross-project settings where domain \ndifferences create significant challenges. Existing vulnerability detection models", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10664-025-10749-4&hl=vi&sa=X&d=5787044264909627309&ei=oNIjad_mAaG7ieoP8Y6WyQc&scisig=ABGrvjJ29zOgzha_sOP3xWytZM2T&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "LMFuzz: Program repair fuzzing based on large language models", "first_label": ["APR", "LLM", "Fuzzing"], "second_label": ["Repair"], "data": "R Lin, R Wang, G Hu, X Xu- Automated Software Engineering, 2026\nGenerating programs using large language models (LLMs) for fuzz testing has \nemerged as a significant testing methodology. While traditional fuzzers can produce \ncorrect programs, their effectiveness is limited by excessive constraints and restricted", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00568-8&hl=vi&sa=X&d=16706984066078411801&ei=oNIjad_mAaG7ieoP8Y6WyQc&scisig=ABGrvjLMTxGR3-Z1Hr556q7Ejx9K&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Beyond Synthetic Benchmarks: Evaluating LLM Performance on Real-World Class-Level Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "M Rahman, SH Khatoonabadi, E Shihab- arXiv preprint arXiv:2510.26130, 2025\nLarge language models (LLMs) have advanced code generation at the function \nlevel, yet their ability to produce correct class-level implementations in authentic \nsoftware projects remains poorly understood. This work introduces a novel", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.26130&hl=vi&sa=X&d=13761241531887805841&ei=oNIjad_mAaG7ieoP8Y6WyQc&scisig=ABGrvjLlYmn4XLej__SC0XdKrFFY&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "LoCoBench-Agent: An Interactive Benchmark for LLM Agents in Long-Context Software Engineering", "first_label": ["LLM"], "second_label": ["Agent"], "data": "J Qiu, Z Liu, Z Liu, R Murthy, J Zhang, H Chen, S Wang- arXiv preprint arXiv, 2025\nAs large language models (LLMs) evolve into sophisticated autonomous agents \ncapable of complex software development tasks, evaluating their real-world \ncapabilities becomes critical. While existing benchmarks like LoCoBench~\\cite", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.13998&hl=vi&sa=X&d=5068327394060475494&ei=oNIjad_mAaG7ieoP8Y6WyQc&scisig=ABGrvjK9zILMF-H5bmo_6Oj44-_r&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "CodeCrash: Exposing LLM Fragility to Misleading Natural Language in Code Reasoning", "first_label": ["LLM", "Code"], "second_label": ["Reasoning"], "data": "MH Lam, C Wang, J Huang, M Lyu- The Thirty-ninth Annual Conference on Neural\nLarge Language Models (LLMs) have recently demonstrated strong capabilities in \ncode-related tasks, but their robustness in code reasoning under perturbations \nremains underexplored. We introduce CodeCrash, a stress-testing framework with", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DCAB0EjD9EK&hl=vi&sa=X&d=13889957657119136301&ei=oNIjad_mAaG7ieoP8Y6WyQc&scisig=ABGrvjLDDoY0GiXO7mB3QF7Zpr9h&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "SecureReviewer: Enhancing Large Language Models for Secure Code Review through Secure-aware Fine-tuning", "first_label": ["LLM", "Code Review", "Code"], "second_label": [], "data": "F Liu, S Liu, Y Zhu, X Lian, L Zhang- arXiv preprint arXiv:2510.26457, 2025\nIdentifying and addressing security issues during the early phase of the development \nlifecycle is critical for mitigating the long-term negative impacts on software systems. \nCode review serves as an effective practice that enables developers to check their", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.26457&hl=vi&sa=X&d=2750772061662092214&ei=oNIjad_mAaG7ieoP8Y6WyQc&scisig=ABGrvjJCIQLgS8ShLO-ChXzeoUuk&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Preconditions and Postconditions as Design Constraints for LLM Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "L Newcomb, A Davidoff, O Ochoa- IEEE Access, 2025\nLarge Language Models (LLMs) have significantly advanced automated code \ngeneration, but current methods predominantly rely on natural language descriptions \nduring prompting. This approach encounters challenges when handling complex", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/10820123/11218044.pdf&hl=vi&sa=X&d=2337714649732748995&ei=oNIjad_mAaG7ieoP8Y6WyQc&scisig=ABGrvjJOfei8fbkAtS9augPuYsaC&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "KTester: Leveraging Domain and Testing Knowledge for More Effective LLM-based Test Generation", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "A Li, M Liu, Z Chen, Z Pei, Z Li, D Dai, Y Wang, Z Zheng- arXiv preprint arXiv, 2025\nAutomated unit test generation using large language models (LLMs) holds great \npromise but often struggles with generating tests that are both correct and \nmaintainable in real-world projects. This paper presents KTester, a novel framework", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.14224&hl=vi&sa=X&d=10983934054869938261&ei=oNIjad_mAaG7ieoP8Y6WyQc&scisig=ABGrvjIa1vtPoJYgQBH-oUV-iEOl&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=7&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "SAINT: Service-level Integration Test Generation with Program Analysis and LLM-based Agents", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation", "Agent"], "data": "R Pan, R Pavuluri, R Huang, R Krishna, T Stennett- arXiv preprint arXiv, 2025\nEnterprise applications are typically tested at multiple levels, with service-level \ntesting playing an important role in validating application functionality. Existing \nservice-level testing tools, especially for RESTful APIs, often employ fuzzing and/or", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.13305&hl=vi&sa=X&d=9022492230427322452&ei=oNIjad_mAaG7ieoP8Y6WyQc&scisig=ABGrvjIMsS1xc9Zre8DmeA3ZJSCx&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=8&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Coverage-Based Harmfulness Testing for LLM Code Transformation", "first_label": ["LLM", "Code", "Software Testing"], "second_label": [], "data": "H Tan, H Wang, D Pressato, Y Xu, SH Tan\nHarmful content embedded in program elements within source code may have \ndetrimental impact on mental health of software developers, and promote harmful \nbehavior. Our key insight is that software developers may introduce harmful content\n\u00a0\nGoogle Scholar gi thng bo ny cho bn v bn ang theo di nhng bi vit mi lin quan n nghin cu ca \nThanh Le-Cong\n.\nLit k cnh bo\nHy thng bo", "link": "https://scholar.google.com/scholar_url?url=https://www.shinhwei.com/HarmfulnessTestingASE.pdf&hl=vi&sa=X&d=3477573746713553799&ei=oNIjad_mAaG7ieoP8Y6WyQc&scisig=ABGrvjJDTN0Mk1UOA2rBuCbdW6Ih&oi=scholaralrt&hist=70gU4M0AAAAJ:5337116523931328826:ABGrvjLqVVXr1S-nGnuJMZNq7zZZ&html=&pos=9&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
